<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Module 6 Module Overview | Course Notes for Introduction to Statistics</title>
  <meta name="description" content="Course notes for Introduction to Statistics." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Module 6 Module Overview | Course Notes for Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for Introduction to Statistics." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Module 6 Module Overview | Course Notes for Introduction to Statistics" />
  
  <meta name="twitter:description" content="Course notes for Introduction to Statistics." />
  

<meta name="author" content="Dr.Â Lauren Cappiello" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-to-inference.html"/>
<link rel="next" href="introduction-to-hypothesis-testing.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Data</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#module-overview"><i class="fa fa-check"></i><b>1.1</b> Module Overview</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#statistics-terminology"><i class="fa fa-check"></i><b>1.2</b> Statistics Terminology</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#data-basics"><i class="fa fa-check"></i><b>1.3</b> Data Basics</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#sampling"><i class="fa fa-check"></i><b>1.4</b> Sampling</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#experimental-design"><i class="fa fa-check"></i><b>1.5</b> Experimental Design</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#graphical-presentations"><i class="fa fa-check"></i><b>1.6</b> Graphical Presentations</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#frequency-distributions"><i class="fa fa-check"></i><b>1.7</b> Frequency Distributions</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="index.html"><a href="index.html#qualitative-variables"><i class="fa fa-check"></i><b>1.7.1</b> Qualitative Variables</a></li>
<li class="chapter" data-level="1.7.2" data-path="index.html"><a href="index.html#quantitative-variables"><i class="fa fa-check"></i><b>1.7.2</b> Quantitative Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="descriptive-measures.html"><a href="descriptive-measures.html"><i class="fa fa-check"></i><b>2</b> Descriptive Measures</a>
<ul>
<li class="chapter" data-level="2.1" data-path="descriptive-measures.html"><a href="descriptive-measures.html#module-overview-1"><i class="fa fa-check"></i><b>2.1</b> Module Overview</a></li>
<li class="chapter" data-level="2.2" data-path="descriptive-measures.html"><a href="descriptive-measures.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>2.2</b> Measures of Central Tendency</a></li>
<li class="chapter" data-level="2.3" data-path="descriptive-measures.html"><a href="descriptive-measures.html#measures-of-variability"><i class="fa fa-check"></i><b>2.3</b> Measures of Variability</a></li>
<li class="chapter" data-level="2.4" data-path="descriptive-measures.html"><a href="descriptive-measures.html#measures-of-position"><i class="fa fa-check"></i><b>2.4</b> Measures of Position</a></li>
<li class="chapter" data-level="2.5" data-path="descriptive-measures.html"><a href="descriptive-measures.html#box-plots"><i class="fa fa-check"></i><b>2.5</b> Box Plots</a></li>
<li class="chapter" data-level="2.6" data-path="descriptive-measures.html"><a href="descriptive-measures.html#descriptive-measures-for-populations"><i class="fa fa-check"></i><b>2.6</b> Descriptive Measures for Populations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability-concepts.html"><a href="probability-concepts.html"><i class="fa fa-check"></i><b>3</b> Probability Concepts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability-concepts.html"><a href="probability-concepts.html#module-overview-2"><i class="fa fa-check"></i><b>3.1</b> Module Overview</a></li>
<li class="chapter" data-level="3.2" data-path="probability-concepts.html"><a href="probability-concepts.html#experiments-sample-spaces-and-events"><i class="fa fa-check"></i><b>3.2</b> Experiments, Sample Spaces, and Events</a></li>
<li class="chapter" data-level="3.3" data-path="probability-concepts.html"><a href="probability-concepts.html#probability-distributions"><i class="fa fa-check"></i><b>3.3</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="probability-concepts.html"><a href="probability-concepts.html#venn-diagrams"><i class="fa fa-check"></i><b>3.3.1</b> Venn Diagrams</a></li>
<li class="chapter" data-level="3.3.2" data-path="probability-concepts.html"><a href="probability-concepts.html#probability-axioms"><i class="fa fa-check"></i><b>3.3.2</b> Probability Axioms</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="probability-concepts.html"><a href="probability-concepts.html#rules-of-probability"><i class="fa fa-check"></i><b>3.4</b> Rules of Probability</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="probability-concepts.html"><a href="probability-concepts.html#addition-rules"><i class="fa fa-check"></i><b>3.4.1</b> Addition Rules</a></li>
<li class="chapter" data-level="3.4.2" data-path="probability-concepts.html"><a href="probability-concepts.html#complements"><i class="fa fa-check"></i><b>3.4.2</b> Complements</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="probability-concepts.html"><a href="probability-concepts.html#conditional-probability"><i class="fa fa-check"></i><b>3.5</b> Conditional Probability</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="probability-concepts.html"><a href="probability-concepts.html#multiplication-rules"><i class="fa fa-check"></i><b>3.5.1</b> Multiplication Rules</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>4</b> Random Variables</a>
<ul>
<li class="chapter" data-level="4.1" data-path="random-variables.html"><a href="random-variables.html#module-overview-3"><i class="fa fa-check"></i><b>4.1</b> Module Overview</a></li>
<li class="chapter" data-level="4.2" data-path="random-variables.html"><a href="random-variables.html#discrete-random-variables"><i class="fa fa-check"></i><b>4.2</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="random-variables.html"><a href="random-variables.html#the-mean-and-standard-deviation"><i class="fa fa-check"></i><b>4.2.1</b> The Mean and Standard Deviation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="random-variables.html"><a href="random-variables.html#the-binomial-distribution"><i class="fa fa-check"></i><b>4.3</b> The Binomial Distribution</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="random-variables.html"><a href="random-variables.html#mean-and-variance"><i class="fa fa-check"></i><b>4.3.1</b> Mean and Variance</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="random-variables.html"><a href="random-variables.html#the-normal-distribution"><i class="fa fa-check"></i><b>4.4</b> The Normal Distribution</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="random-variables.html"><a href="random-variables.html#the-standard-normal-distribution"><i class="fa fa-check"></i><b>4.4.1</b> The Standard Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="random-variables.html"><a href="random-variables.html#area-under-the-standard-normal-curve"><i class="fa fa-check"></i><b>4.5</b> Area Under the Standard Normal Curve</a></li>
<li class="chapter" data-level="4.6" data-path="random-variables.html"><a href="random-variables.html#working-with-normally-distributed-variables"><i class="fa fa-check"></i><b>4.6</b> Working with Normally Distributed Variables</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="random-variables.html"><a href="random-variables.html#normal-distribution-probabilities"><i class="fa fa-check"></i><b>4.6.1</b> Normal Distribution Probabilities</a></li>
<li class="chapter" data-level="4.6.2" data-path="random-variables.html"><a href="random-variables.html#empirical-rule-for-variables"><i class="fa fa-check"></i><b>4.6.2</b> Empirical Rule for Variables</a></li>
<li class="chapter" data-level="4.6.3" data-path="random-variables.html"><a href="random-variables.html#percentiles"><i class="fa fa-check"></i><b>4.6.3</b> Percentiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html"><i class="fa fa-check"></i><b>5</b> Introduction to Inference</a></li>
<li class="chapter" data-level="6" data-path="module-overview-4.html"><a href="module-overview-4.html"><i class="fa fa-check"></i><b>6</b> Module Overview</a>
<ul>
<li class="chapter" data-level="6.1" data-path="module-overview-4.html"><a href="module-overview-4.html#sampling-distributions"><i class="fa fa-check"></i><b>6.1</b> Sampling Distributions</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="module-overview-4.html"><a href="module-overview-4.html#sampling-error"><i class="fa fa-check"></i><b>6.1.1</b> Sampling Error</a></li>
<li class="chapter" data-level="6.1.2" data-path="module-overview-4.html"><a href="module-overview-4.html#the-sampling-distribution-of-barx"><i class="fa fa-check"></i><b>6.1.2</b> The Sampling Distribution of <span class="math inline">\(\bar{X}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="module-overview-4.html"><a href="module-overview-4.html#developing-confidence-intervals"><i class="fa fa-check"></i><b>6.2</b> Developing Confidence Intervals</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="module-overview-4.html"><a href="module-overview-4.html#interpreting-a-confidence-interval"><i class="fa fa-check"></i><b>6.2.1</b> Interpreting a Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="module-overview-4.html"><a href="module-overview-4.html#other-levels-of-confidence"><i class="fa fa-check"></i><b>6.3</b> Other Levels of Confidence</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="module-overview-4.html"><a href="module-overview-4.html#confidence-level-precision-and-sample-size"><i class="fa fa-check"></i><b>6.3.1</b> Confidence Level, Precision, and Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="module-overview-4.html"><a href="module-overview-4.html#confidence-intervals-sigma-unknown"><i class="fa fa-check"></i><b>6.4</b> Confidence Intervals, <span class="math inline">\(\sigma\)</span> Unknown</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="module-overview-4.html"><a href="module-overview-4.html#the-t-distribution"><i class="fa fa-check"></i><b>6.4.1</b> The T-Distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="module-overview-4.html"><a href="module-overview-4.html#summary-of-confidence-interval-settings"><i class="fa fa-check"></i><b>6.5</b> Summary of Confidence Interval Settings</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html"><i class="fa fa-check"></i><b>7</b> Introduction to Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#module-overview-5"><i class="fa fa-check"></i><b>7.1</b> Module Overview</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>8</b> Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="regression.html"><a href="regression.html#module-overview-6"><i class="fa fa-check"></i><b>8.1</b> Module Overview</a></li>
<li class="chapter" data-level="8.2" data-path="regression.html"><a href="regression.html#linear-equations-with-one-independent-variable"><i class="fa fa-check"></i><b>8.2</b> Linear Equations with One Independent Variable</a></li>
<li class="chapter" data-level="8.3" data-path="regression.html"><a href="regression.html#regression-1"><i class="fa fa-check"></i><b>8.3</b> Regression</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Course Notes for Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="module-overview-4" class="section level1" number="6">
<h1><span class="header-section-number">Module 6</span> Module Overview</h1>
<p>This module will bridge the gap between our discussion on the normal distribution and our first forays into statistical inference. As it turns out, much of the statistical inference we will use relies on the normal distribution and the t-distribution, which we will introduce in this module. We begin our study of statistical inference by learning about confidence intervals.</p>
<p><strong>Module Learning Objectives/Outcomes</strong></p>
<ol style="list-style-type: decimal">
<li>Find the distribution of a sample mean.</li>
<li>Estimate probabilities for a sample mean.</li>
<li>Calculate and interpret confidence intervals for a population mean.</li>
<li>Use the standard normal and t-distributions to find critical values.</li>
</ol>
<p>This moduleâs outcomes correspond to course outcome (6) apply statistical inference techniques of parameter estimation such as point estimation and confidence interval estimation and (7) apply techniques of testing various statistical hypotheses concerning population parameters.</p>
<div id="sampling-distributions" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Sampling Distributions</h2>
<div id="sampling-error" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Sampling Error</h3>
<p>We want to use a sample to learn something about a population, but no sample is perfect! <strong>Sampling error</strong> is the error resulting from using a sample to estimate a population characteristic.</p>
<p>If we use a sample mean <span class="math inline">\(\bar{x}\)</span> to estimate <span class="math inline">\(\mu\)</span>, chances are that <span class="math inline">\(\bar{x}\ne\mu\)</span> (they might be close butâ¦ they might not be!). We will consider</p>
<ul>
<li>How close <em>is</em> <span class="math inline">\(\bar{x}\)</span> to <span class="math inline">\(\mu\)</span>?</li>
<li>What if we took many samples and calculated <span class="math inline">\(\bar{x}\)</span> many times?
<ul>
<li>How would that relate to <span class="math inline">\(\mu\)</span>?</li>
<li>What would be the distribution of these values?</li>
</ul></li>
</ul>
<p>The distribution of a statistic (across all possible samples of size <span class="math inline">\(n\)</span>) is called the <strong>sampling distribution</strong>. We will focus primarily on the distribution of the sample mean.</p>
<p>For a variable <span class="math inline">\(x\)</span> and given a sample size <span class="math inline">\(n\)</span>, the distribution of <span class="math inline">\(\bar{x}\)</span> is alled the <strong>sampling distribution of the sample mean</strong> or the <strong>distribution of <span class="math inline">\(\boldsymbol{\bar{x}}\)</span></strong>.</p>
<blockquote>
<p><em>Example</em>: Suppose our population is the five starting players on a particular basketball team. We are interested in their heights (measures in inches). The full population data is</p>
<table>
<thead>
<tr class="header">
<th align="left">Player</th>
<th align="center">A</th>
<th align="center">B</th>
<th align="center">C</th>
<th align="center">D</th>
<th align="center">E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Height</td>
<td align="center">76</td>
<td align="center">78</td>
<td align="center">79</td>
<td align="center">81</td>
<td align="center">86</td>
</tr>
</tbody>
</table>
<p>The population mean is <span class="math inline">\(\mu=80\)</span>. Consider all possible samples of size <span class="math inline">\(n=2\)</span>:</p>
<table>
<thead>
<tr class="header">
<th align="left">Sample</th>
<th align="center">A,B</th>
<th align="center">A,C</th>
<th align="center">A,D</th>
<th align="center">A,E</th>
<th align="center">B,C</th>
<th align="center">B,D</th>
<th align="center">B,E</th>
<th align="center">C,D</th>
<th align="center">C,E</th>
<th align="center">D,E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\bar{x}\)</span></td>
<td align="center">77</td>
<td align="center">77.5</td>
<td align="center">78.5</td>
<td align="center">81.0</td>
<td align="center">78.5</td>
<td align="center">79.5</td>
<td align="center">82.0</td>
<td align="center">80.0</td>
<td align="center">82.5</td>
<td align="center">83.5</td>
</tr>
</tbody>
</table>
<p>There are 10 possible samples of size 2. Of these samples, 10% have means exactly equal to <span class="math inline">\(\mu\)</span> (for a <em>random</em> sample of size 2, youâd have a 10% chance to find <span class="math inline">\(\bar{x}=\mu\)</span>â¦ and a 90% chance not to!).</p>
</blockquote>
<p>In general, the larger the sample size, the smaller the sampling error tends to be in estimating <span class="math inline">\(\mu\)</span> using <span class="math inline">\(\bar{x}\)</span>.</p>
<p>In practice, we have one sample and <span class="math inline">\(\mu\)</span> is unknown. We also have limited resources to collect data, so it may not be feasible to collect a very large sample.</p>
<p>The mean of the distribution of <span class="math inline">\(\bar{x}\)</span> is <span class="math inline">\(\mu_{\bar{X}}=\mu\)</span> and the standard deviation is <span class="math inline">\(\sigma_{\bar{X}}=\sigma/\sqrt{n}\)</span>. We refer to the standard deviation of a sampling distribution as <strong>standard error</strong>. (Note that this standard error formula is built for very large populations, so it will not work well for our basketball players. This is okay! We usually work with populations so large that we treat them as âinfinite.â)</p>
<blockquote>
<p><em>Example</em>: The mean living space for a detatched single family home in the United States is 1742 ft<span class="math inline">\(^2\)</span> with a standard deviation of 568 square feet. (Does that mean seem huge to anyone else??) For samples of 25 homes, determine the mean and standard error of <span class="math inline">\(\bar{x}\)</span>.</p>
<p>Using our formulae: <span class="math display">\[\mu_{\bar{X}} = \mu = 1742\]</span> and <span class="math display">\[\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{568}{\sqrt{25}} = 113.6.\]</span></p>
</blockquote>
</div>
<div id="the-sampling-distribution-of-barx" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> The Sampling Distribution of <span class="math inline">\(\bar{X}\)</span></h3>
<p>First, we consider the setting where <span class="math inline">\(X\)</span> is Normal(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>). The plots below show (A) a random sample of 1000 from a Normal(100, 25) distribution and (B) the approximate sampling distribution of <span class="math inline">\(\bar{X}\)</span> when X is Normal(100, 25).</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Notice how the x-axis changes from one plot to the next.</p>
<p>In fact, if <span class="math inline">\(X\)</span> is Normal(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>), then <span class="math inline">\(\bar{X}\)</span> is Normal(<span class="math inline">\(\mu_{\bar{X}}=\mu\)</span>, <span class="math inline">\(\sigma_{\bar{X}}=\sigma/\sqrt{n}\)</span>).</p>
<center>
<font size='4'><strong>Central Limit Theorem</strong>
</center>
<p></font></p>
<p>For relatively large sample sizes, the random variable <span class="math inline">\(\bar{X}\)</span> is approximately normally distributed <em>regardless of the distribution of</em> <span class="math inline">\(X\)</span>: <span class="math display">\[\bar{X}\text{ is Normal}(\mu_{\bar{X}}=\mu, \sigma_{\bar{X}}=\sigma/\sqrt{n}).\]</span></p>
<p>Notes</p>
<ul>
<li>This approximation improves with increasing sample size.</li>
<li>In general, ârelatively largeâ means sample sizes <span class="math inline">\(n \ge 30\)</span>.</li>
</ul>
</div>
</div>
<div id="developing-confidence-intervals" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Developing Confidence Intervals</h2>
<p>Recall: A <strong>point estimate</strong> is a single-value estimate of a population parameter. We say that a statistic is an <strong>unbiased estimator</strong> if the mean of its distribution is equal to the population parameter. Otherwise, it is a <strong>biased estimator</strong>.</p>
<p><em>Comment</em> Remember how our formula for standard deviation, the âmean squared devianceâ divides by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>? We do this so that <span class="math inline">\(s\)</span> is an <em>unbiased</em> estimate of <span class="math inline">\(\sigma\)</span>.</p>
<p>Ideally, we want estimates that are unbiased with small standard error. For example, a sample mean (unbiased) with a large sample size (results in smaller standard error).</p>
<p>Point estimates are useful, but they only give us so much information. The variability of an estimate is also important!</p>
<blockquote>
<p><em>Example</em> Think about estimating what tomorrowâs weather will be like. If itâs May in Sacramento, the average high temperature is 82 degrees Fahrenheit, but itâs not uncommon to have highs anywhere from 75 to 90! Since the highs are so <em>variable</em>, itâs hard to be confident using 82 to predict tomorrowâs weather.</p>
<p>On the flip side, think about July in Phoenix. The average high is 106 degrees Fahrenheit. In Phoenix, itâs uncommon to have a July day with a high below 100. Since the highs are <em>not variable</em>, you could feel pretty confidence using 105 to predict tomorrowâs weather.</p>
</blockquote>
<p>Take a look at these two boxplots:</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Both samples are size <span class="math inline">\(n=100\)</span> and have <span class="math inline">\(\bar{x}=0\)</span>, which would be our point estimate for <span class="math inline">\(\mu\)</span>â¦ but Variable 1 has a standard deviation of <span class="math inline">\(\sigma=0.5\)</span> and Variable 2 has standard deviation <span class="math inline">\(\sigma=5\)</span>. As a result, we can be more confident in our estimate of the population mean for Variable 1 than for Variable 2.</p>
<p>We want to formalize this idea of confidence in our estimates. A <strong>confidence interval</strong> is an interval of numbers based on the point estimate of the parameter. Say we want to be 95% confident about a statement. In Statistics, this means that we have arrived at our statement using a method that will give us a correct statement 95% of the time.</p>
<p>Assume we are taking a sample from a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. We will assume the value of <span class="math inline">\(\sigma\)</span> is known to us. Then <span class="math inline">\(\bar{X}\)</span> is Normal(<span class="math inline">\(\mu, \sigma/\sqrt{n}\)</span>). If we standardize <span class="math inline">\(\bar{X}\)</span>, we get <span class="math display">\[Z = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}.\]</span></p>
<p>We want some interval <span class="math inline">\((a,b)\)</span>. We will start by considering <span class="math inline">\(a &lt; Z &lt; b\)</span>, so <span class="math inline">\(a &lt; Z\)</span> and <span class="math inline">\(Z &lt; b\)</span> (or <span class="math inline">\(b &gt; Z\)</span>). Then</p>
<span class="math display">\[\begin{aligned}
Z &amp;&lt; b\\
\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} &amp;&lt; b\\
\bar{X}-\mu &amp;&lt; b\sigma/\sqrt{n} \\
\bar{X}-b\sigma/\sqrt{n} &amp;&lt; \mu 
\end{aligned}\]</span>
<p>and</p>
<span class="math display">\[\begin{aligned}
a &amp;&lt; Z  \\
a &amp;&lt; \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \\
a\sigma/\sqrt{n} &amp;&lt; \bar{X}-\mu \\
\mu &amp;&lt; \bar{X}-a\sigma/\sqrt{n}
\end{aligned}\]</span>
<p>putting these together, <span class="math display">\[ \bar{X}-b\frac{\sigma}{\sqrt{n}} &lt; \mu &lt;  \bar{X}-a\frac{\sigma}{\sqrt{n}}.\]</span> If we want to be 95% confident, then we want <span class="math inline">\(P(a &lt; Z &lt; b)=0.95\)</span>: <span class="math display">\[P\left(\bar{X}-b\frac{\sigma}{\sqrt{n}} &lt; \mu &lt;  \bar{X}-a\frac{\sigma}{\sqrt{n}}\right) = 0.95.\]</span> To calculate the 95% confidence interval, we need to find <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that <span class="math inline">\(P(a &lt; Z &lt; b)=0.95\)</span>.</p>
<p>We want this interval to be as narrow (small) as possible. Why? Narrower intervals are more informative. If I say Iâm 95% confidence that tomorrowâs high will be between -100 and 200 degrees Fahrenheit, thatâs a useless interval. If I change it to between 70 and 100, thatâs a little better. Changing it to between 85 and 90 is even better. This is what we mean by more informative.</p>
<p>It turns out that, with a symmetric distribution like the normal distribution, the way to make a confidence interval as narrow as possible is to take advantage of this symmetry. Each of the plots below show a shaded area of 0.95. The narrowest interval (along the horizontal axis) is the first interval, which is shaded on <span class="math inline">\((-1.96 &lt; z &lt; 1.96)\)</span>.</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>The confidence interval, then, is <span class="math display">\[\left(\bar{x} - z_*\frac{\sigma}{\sqrt{n}}, \bar{x} + z_*\frac{\sigma}{\sqrt{n}}\right)\]</span> where <span class="math inline">\(z_* = 1.96\)</span>. The midpoint of this interval is <span class="math inline">\(\bar{x}\)</span>. The value of <span class="math display">\[z_*\frac{\sigma}{\sqrt{n}}\]</span> is called the <strong>margin of error</strong>.</p>
<div id="interpreting-a-confidence-interval" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Interpreting a Confidence Interval</h3>
<p>To interpret a confidence interval, we need to think back to our definition of probability as âthe proportion of times is would occur if the experiment were run infinitely many times.â In the confidence interval case, if an experiment is run infinitely many times, the true value of <span class="math inline">\(\mu\)</span> will be contained in 95% of the intervals.</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>The graphic above shows 95% confidence intervals for 100 samples of size <span class="math inline">\(n=60\)</span> drawn from a population with mean <span class="math inline">\(\mu=80\)</span> and standard deviation <span class="math inline">\(\sigma=25\)</span>. Each sampleâs confidence interval is represented by a horizontal line. The dot in the middle of each is the sample mean. When a confidence interval does <em>not</em> capture the population mean <span class="math inline">\(\mu\)</span>, the line is printed in red. Based on this concept of repeated sampling, we would expect about 95% of these intervals to capture <span class="math inline">\(\mu\)</span>. In fact, 96 of the 100 intervals capture <span class="math inline">\(\mu\)</span>.</p>
<p>Finally, when you interpret a confidence interval, it is important to do so in the context of the problem.</p>
<blockquote>
<p><em>Example</em> The preferred keyboard height for typists is approximately normally distributed with <span class="math inline">\(\sigma=2.0\)</span>. A sample of size <span class="math inline">\(n=31\)</span>, resulted in a mean prefered keyboard height of <span class="math inline">\(80 cm\)</span>. Find and interpret a 95% confidence interval for keyboard height.</p>
<p>The interval is <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}} = 80.0 \pm 1.96\times\frac{2.0}{\sqrt{31}} = 80.0 \pm 0.70 = (79.3, 80.7).\]</span> Interpretation:We can be 95% confident that the mean preferred keyboard height for typists is between 79.3cm and 80.7cm.</p>
</blockquote>
<p>Notice that I kept the interpretation simple! Thatâs okay - just be sure you are <em>also</em> able to explain what it means to be 95% confident (using the concept of repeated sampling).</p>
<p>Common mistakes:</p>
<ul>
<li>It is NOT accurate to say that âthe probability that <span class="math inline">\(\mu\)</span> is in the confidence interval is 0.95.â The parameter <span class="math inline">\(\mu\)</span> is some fixed quantity and itâs either in the interval or it isnât.</li>
<li>We are NOT â95% confident that <span class="math inline">\(\bar{x}\)</span> is in the interval.â The value <span class="math inline">\(\bar{x}\)</span> is some known quantity and itâs always in the interval.</li>
</ul>
</div>
</div>
<div id="other-levels-of-confidence" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Other Levels of Confidence</h2>
<p>While the 95% confidence interval is common in research, thereâs nothing inherently special about it. You could calculate a 90%, a 99%, or - if youâre feeling spicy - something like a 43.8% confidence interval. These numbers are called the <strong>confidence level</strong> and they represent the proportion of times that the parameter will fall in the interval (if we took many samples).</p>
<p>The 100(1-<span class="math inline">\(\alpha\)</span>)% confidence interval for <span class="math inline">\(\mu\)</span> is given by <span class="math display">\[\bar{x}\pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\]</span> where <span class="math inline">\(z_{\alpha/2}\)</span> is the <span class="math inline">\((\alpha/2)\)</span>th percentile of the standard normal distribution. The value <span class="math inline">\(z_{\alpha/2}\)</span> is called the <strong>critical value</strong>.</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-25-1.png" width="672" />
We can find critical values in <code>R</code> using the same command we used to find percentiles: <code>qnorm(p)</code>. We want a 100(1-<span class="math inline">\(\alpha\)</span>) confidence interval, so we need to quickly solve for <span class="math inline">\(\alpha\)</span> and divide by 2. For example, for a 98% interval, <span class="math display">\[100(1-$\alpha$) = 98 \implies \alpha=0.02\]</span> Then <span class="math inline">\(\alpha/2 = 0.01\)</span> and</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="module-overview-4.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.01</span>)</span></code></pre></div>
<pre><code>## [1] -2.326348</code></pre>
<p>So the critical value is <span class="math inline">\(z_{\alpha/2}=2.326\)</span>. Notice that I dropped the negative sign here. Thatâs because our formula uses <span class="math inline">\(\pm z_{\alpha/2}\)</span>, so the sign doesnât matter. Iâll always ignore that negative for critical values. As long as you write your interval as <span class="math inline">\((\text{smaller number}, \text{bigger number})\)</span>, itâs all good.</p>
<center>
<font size='4'><strong>Common Critical Values</strong>
</center>
<p></font></p>
<table>
<thead>
<tr class="header">
<th align="center">Confidence Level</th>
<th align="center"><span class="math inline">\(\alpha\)</span></th>
<th align="center">Critical Value, $z_{/2}</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">90%</td>
<td align="center">0.10</td>
<td align="center">1.645</td>
</tr>
<tr class="even">
<td align="center">95%</td>
<td align="center">0.05</td>
<td align="center">1.90</td>
</tr>
<tr class="odd">
<td align="center">99%</td>
<td align="center">0.01</td>
<td align="center">2.575</td>
</tr>
</tbody>
</table>
<div id="confidence-level-precision-and-sample-size" class="section level3" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Confidence Level, Precision, and Sample Size</h3>
<p>If we can be 99% confident (or even higher), why do we tend to âsettleâ for 95%?? Take a look at the common critical values (above) and the confidence interval formula <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}.\]</span> What will higher levels of confidence do to this interval? Think back to the intuitive interval width explanation with the weather. Mathematically, the same thing will happen: the interval will get wider! And remember, a narrow interval is a more informative interval. There is a trade off here between interval width and confidence. In general, the scientific community has settled on 95% as a compromise between the two, but different fields may use different levels of confidence.</p>
<p>There is one other thing we can control in the confidence interval: the sample size <span class="math inline">\(n\)</span>. One strategy is to specify the confidence level and the maximum acceptable interval width and use these to determine sample size. We know that <span class="math display">\[\text{interval width}=2z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\]</span> Letting interval width equal <span class="math inline">\(w\)</span>, we can solve for <span class="math inline">\(n\)</span>: <span class="math display">\[ n = \left(2z_{\alpha/2}\frac{\sigma}{w}\right)^2\]</span> Alternately, we may specify a maximum margin of error <span class="math inline">\(m\)</span> instead: <span class="math display">\[ n = \left(z_{\alpha/2}\frac{\sigma}{m}\right)^2\]</span></p>
<p>A few comments:</p>
<ul>
<li>As desired width/margin of error decreases, <span class="math inline">\(n\)</span> will increase.</li>
<li>As <span class="math inline">\(\sigma\)</span> increases, <span class="math inline">\(n\)</span> will also increase. (More population variability will necessitate a larger sample size.)</li>
<li>As confidence level increases, <span class="math inline">\(n\)</span> will also increase.</li>
</ul>
</div>
</div>
<div id="confidence-intervals-sigma-unknown" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Confidence Intervals, <span class="math inline">\(\sigma\)</span> Unknown</h2>
<p>In practice, the value of <span class="math inline">\(\sigma\)</span> is almost never knownâ¦ but we know that we can estimate <span class="math inline">\(\sigma\)</span> using <span class="math inline">\(s\)</span>. Can we plug in <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span>? Sometimes!</p>
<p>Remember the Central Limit Theorem (Section 5.1)? For samples of size <span class="math inline">\(n \ge 30\)</span>, <span class="math inline">\(\bar{X}\)</span> will be approximately normal even if <span class="math inline">\(X\)</span> isnât. In this case, we can plug in <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span>: <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{s}{\sqrt{n}}.\]</span></p>
<p>Too easy? Okay, we do need to consider the setting where <span class="math inline">\(n &lt; 30\)</span>, which will require a bit of additional work.</p>
<div id="the-t-distribution" class="section level3" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> The T-Distribution</h3>
<p>Enter: the t-distribution. If <span class="math display">\[Z = \frac{\bar{Z}-\mu}{\sigma/\sqrt{n}}\]</span> has a standard normal distribution, the slightly modified <span class="math display">\[T = \frac{\bar{X}-\mu}{s/\sqrt{n}}\]</span> has what we call the <strong>t-distribution</strong> with <span class="math inline">\(n-1\)</span> <strong>degrees of freedom</strong>. The only thing we need to know about degrees of freedom is that <span class="math inline">\(df=n-1\)</span> is the t-distributionâs only parameter.</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>The t-distribution is symmetric and always centered at 0. When <span class="math inline">\(n\ge30\)</span>, the t-distribution is approximately equivalent to the standard normal distribution. For smaller sample sizes, the t-distribution has more area in the tails (and therefore less area in the center of the distribution).</p>
<p>For a sample of size <span class="math inline">\(n &lt; 30\)</span>, we plug in <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span> and use a t critical value (instead of a z critical value): <span class="math display">\[\bar{x} \pm t_{df, \alpha/2}\frac{s}{\sqrt{n}}.\]</span></p>
<p>To find a t critical value, we will again use <code>R</code>, now with the command <code>qt(p, df)</code>. (Notice that this is similar to the command for the standard normal distribution, but instead of ânormâ for normal it has âtâ for the t-distribution.) For example, for a 98% interval with a sample size of 15, <span class="math display">\[100(1-\alpha) = 98 \implies \alpha=0.02\]</span> Then <span class="math inline">\(\alpha/2 = 0.01\)</span> and <span class="math inline">\(df=15-1=14\)</span>.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="module-overview-4.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.01</span>, <span class="at">df=</span><span class="dv">14</span>)</span></code></pre></div>
<pre><code>## [1] -2.624494</code></pre>
<p>which gives the t critical value <span class="math inline">\(t_{14,\alpha/2} = 2.624\)</span>. Notice again that I am able to ignore the sign because our formula uses <span class="math inline">\(\pm t_{df,\alpha/2}\)</span>.</p>
</div>
</div>
<div id="summary-of-confidence-interval-settings" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Summary of Confidence Interval Settings</h2>
<center>
<font size='4'><strong>Setting 1: <span class="math inline">\(\mu\)</span> is target parameter, <span class="math inline">\(X\)</span> is normal, <span class="math inline">\(\sigma\)</span> known</strong>
</center>
<p></font></p>
<p><span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}.\]</span></p>
<center>
<font size='4'><strong>Setting 2: <span class="math inline">\(\mu\)</span> is target parameter, <span class="math inline">\(n \ge 30\)</span>, <span class="math inline">\(\sigma\)</span> unknown</strong>
</center>
<p></font></p>
<p><span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{s}{\sqrt{n}}.\]</span></p>
<center>
<font size='4'><strong>Setting 3: <span class="math inline">\(\mu\)</span> is target parameter, <span class="math inline">\(n &lt; 30\)</span>, <span class="math inline">\(\sigma\)</span> unknown</strong>
</center>
<p></font></p>
<p><span class="math display">\[\bar{x} \pm t_{df, \alpha/2}\frac{s}{\sqrt{n}}.\]</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introduction-to-hypothesis-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IntroStats.pdf", "IntroStats.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
