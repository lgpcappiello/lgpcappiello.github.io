<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Inference: Comparing Parameters | Introduction to Statistics</title>
  <meta name="description" content="Chapter 8 Inference: Comparing Parameters | Introduction to Statistics." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Inference: Comparing Parameters | Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Chapter 8 Inference: Comparing Parameters | Introduction to Statistics." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Inference: Comparing Parameters | Introduction to Statistics" />
  
  <meta name="twitter:description" content="Chapter 8 Inference: Comparing Parameters | Introduction to Statistics." />
  

<meta name="author" content="Dr.Â Lauren Cappiello" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inference-for-a-proportion.html"/>
<link rel="next" href="chi-square-tests.html"/>
<script src="libs/header-attrs-2.20.1/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistics</a></li>

<li class="divider"></li>
<li><a href="index.html#welcome-to-statistics" id="toc-welcome-to-statistics">Welcome to Statistics!</a>
<ul>
<li><a href="index.html#course-learning-outcomes" id="toc-course-learning-outcomes">Course Learning Outcomes</a></li>
<li><a href="index.html#for-the-instructor" id="toc-for-the-instructor">For the Instructor</a></li>
<li><a href="index.html#for-the-student" id="toc-for-the-student">For the Student</a>
<ul>
<li><a href="index.html#r-programming" id="toc-r-programming">R Programming</a></li>
</ul></li>
</ul></li>
<li><a href="introduction-to-data.html#introduction-to-data" id="toc-introduction-to-data"><span class="toc-section-number">1</span> Introduction to Data</a>
<ul>
<li><a href="introduction-to-data.html#chapter-overview" id="toc-chapter-overview"><span class="toc-section-number">1.1</span> Chapter Overview</a></li>
<li><a href="introduction-to-data.html#statistics-terminology" id="toc-statistics-terminology"><span class="toc-section-number">1.2</span> Statistics Terminology</a>
<ul>
<li><a href="introduction-to-data.html#r-entering-data" id="toc-r-entering-data">R: Entering Data</a></li>
<li><a href="introduction-to-data.html#section-exercises" id="toc-section-exercises">Section Exercises</a></li>
</ul></li>
<li><a href="introduction-to-data.html#sampling-and-design" id="toc-sampling-and-design"><span class="toc-section-number">1.3</span> Sampling and Design</a>
<ul>
<li><a href="introduction-to-data.html#statistical-sampling" id="toc-statistical-sampling"><span class="toc-section-number">1.3.1</span> Statistical Sampling</a></li>
<li><a href="introduction-to-data.html#experimental-design" id="toc-experimental-design"><span class="toc-section-number">1.3.2</span> Experimental Design</a></li>
<li><a href="introduction-to-data.html#r-random-number-generation" id="toc-r-random-number-generation">R: Random Number Generation</a></li>
<li><a href="introduction-to-data.html#section-exercises-1" id="toc-section-exercises-1">Section Exercises</a></li>
</ul></li>
<li><a href="introduction-to-data.html#frequency-distributions" id="toc-frequency-distributions"><span class="toc-section-number">1.4</span> Frequency Distributions</a>
<ul>
<li><a href="introduction-to-data.html#qualitative-variables" id="toc-qualitative-variables"><span class="toc-section-number">1.4.1</span> Qualitative Variables</a></li>
<li><a href="introduction-to-data.html#quantitative-variables" id="toc-quantitative-variables"><span class="toc-section-number">1.4.2</span> Quantitative Variables</a></li>
<li><a href="introduction-to-data.html#r-histograms" id="toc-r-histograms">R: Histograms</a></li>
</ul></li>
</ul></li>
<li><a href="descriptive-measures.html#descriptive-measures" id="toc-descriptive-measures"><span class="toc-section-number">2</span> Descriptive Measures</a>
<ul>
<li><a href="descriptive-measures.html#chapter-overview-1" id="toc-chapter-overview-1"><span class="toc-section-number">2.1</span> Chapter Overview</a></li>
<li><a href="descriptive-measures.html#measures-of-central-tendency" id="toc-measures-of-central-tendency"><span class="toc-section-number">2.2</span> Measures of Central Tendency</a>
<ul>
<li><a href="descriptive-measures.html#r-finding-measures-of-center" id="toc-r-finding-measures-of-center">R: Finding Measures of Center</a></li>
</ul></li>
<li><a href="descriptive-measures.html#measures-of-variability" id="toc-measures-of-variability"><span class="toc-section-number">2.3</span> Measures of Variability</a>
<ul>
<li><a href="descriptive-measures.html#r-finding-measures-of-variability" id="toc-r-finding-measures-of-variability">R: Finding Measures of Variability</a></li>
</ul></li>
<li><a href="descriptive-measures.html#measures-of-position" id="toc-measures-of-position"><span class="toc-section-number">2.4</span> Measures of Position</a>
<ul>
<li><a href="descriptive-measures.html#box-plots" id="toc-box-plots"><span class="toc-section-number">2.4.1</span> Box Plots</a></li>
<li><a href="descriptive-measures.html#r-measures-of-position" id="toc-r-measures-of-position">R: Measures of Position</a></li>
<li><a href="descriptive-measures.html#r-box-plots" id="toc-r-box-plots">R: Box Plots</a></li>
</ul></li>
<li><a href="descriptive-measures.html#descriptive-measures-for-populations" id="toc-descriptive-measures-for-populations"><span class="toc-section-number">2.5</span> Descriptive Measures for Populations</a></li>
</ul></li>
<li><a href="probability-concepts.html#probability-concepts" id="toc-probability-concepts"><span class="toc-section-number">3</span> Probability Concepts</a>
<ul>
<li><a href="probability-concepts.html#chapter-overview-2" id="toc-chapter-overview-2"><span class="toc-section-number">3.1</span> Chapter Overview</a></li>
<li><a href="probability-concepts.html#experiments-sample-spaces-and-events" id="toc-experiments-sample-spaces-and-events"><span class="toc-section-number">3.2</span> Experiments, Sample Spaces, and Events</a></li>
<li><a href="probability-concepts.html#probability-distributions" id="toc-probability-distributions"><span class="toc-section-number">3.3</span> Probability Distributions</a>
<ul>
<li><a href="probability-concepts.html#venn-diagrams" id="toc-venn-diagrams"><span class="toc-section-number">3.3.1</span> Venn Diagrams</a></li>
<li><a href="probability-concepts.html#probability-axioms" id="toc-probability-axioms"><span class="toc-section-number">3.3.2</span> Probability Axioms</a></li>
<li><a href="probability-concepts.html#exercises" id="toc-exercises">Exercises</a></li>
</ul></li>
<li><a href="probability-concepts.html#rules-of-probability" id="toc-rules-of-probability"><span class="toc-section-number">3.4</span> Rules of Probability</a>
<ul>
<li><a href="probability-concepts.html#addition-rules" id="toc-addition-rules"><span class="toc-section-number">3.4.1</span> Addition Rules</a></li>
<li><a href="probability-concepts.html#complements" id="toc-complements"><span class="toc-section-number">3.4.2</span> Complements</a></li>
</ul></li>
<li><a href="probability-concepts.html#conditional-probability" id="toc-conditional-probability"><span class="toc-section-number">3.5</span> Conditional Probability</a>
<ul>
<li><a href="probability-concepts.html#multiplication-rules" id="toc-multiplication-rules"><span class="toc-section-number">3.5.1</span> Multiplication Rules</a></li>
</ul></li>
</ul></li>
<li><a href="random-variables.html#random-variables" id="toc-random-variables"><span class="toc-section-number">4</span> Random Variables</a>
<ul>
<li><a href="random-variables.html#chapter-overview-3" id="toc-chapter-overview-3"><span class="toc-section-number">4.1</span> Chapter Overview</a></li>
<li><a href="random-variables.html#discrete-random-variables" id="toc-discrete-random-variables"><span class="toc-section-number">4.2</span> Discrete Random Variables</a>
<ul>
<li><a href="random-variables.html#the-mean-and-standard-deviation" id="toc-the-mean-and-standard-deviation"><span class="toc-section-number">4.2.1</span> The Mean and Standard Deviation</a></li>
</ul></li>
<li><a href="random-variables.html#the-binomial-distribution" id="toc-the-binomial-distribution"><span class="toc-section-number">4.3</span> The Binomial Distribution</a>
<ul>
<li><a href="random-variables.html#mean-and-variance" id="toc-mean-and-variance"><span class="toc-section-number">4.3.1</span> Mean and Variance</a></li>
<li><a href="random-variables.html#binomial-probabilities-in-r" id="toc-binomial-probabilities-in-r">Binomial Probabilities in R</a></li>
</ul></li>
<li><a href="random-variables.html#the-normal-distribution" id="toc-the-normal-distribution"><span class="toc-section-number">4.4</span> The Normal Distribution</a>
<ul>
<li><a href="random-variables.html#the-standard-normal-distribution" id="toc-the-standard-normal-distribution"><span class="toc-section-number">4.4.1</span> The Standard Normal Distribution</a></li>
</ul></li>
<li><a href="random-variables.html#area-under-the-standard-normal-curve" id="toc-area-under-the-standard-normal-curve"><span class="toc-section-number">4.5</span> Area Under the Standard Normal Curve</a>
<ul>
<li><a href="random-variables.html#r-normal-distribution-probabilities" id="toc-r-normal-distribution-probabilities">R: Normal Distribution Probabilities</a></li>
</ul></li>
<li><a href="random-variables.html#working-with-normally-distributed-variables" id="toc-working-with-normally-distributed-variables"><span class="toc-section-number">4.6</span> Working with Normally Distributed Variables</a>
<ul>
<li><a href="random-variables.html#normal-distribution-probabilities" id="toc-normal-distribution-probabilities"><span class="toc-section-number">4.6.1</span> Normal Distribution Probabilities</a></li>
<li><a href="random-variables.html#empirical-rule-for-variables" id="toc-empirical-rule-for-variables"><span class="toc-section-number">4.6.2</span> Empirical Rule for Variables</a></li>
<li><a href="random-variables.html#percentiles" id="toc-percentiles"><span class="toc-section-number">4.6.3</span> Percentiles</a></li>
</ul></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#introduction-to-confidence-intervals" id="toc-introduction-to-confidence-intervals"><span class="toc-section-number">5</span> Introduction to Confidence Intervals</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#chapter-overview-4" id="toc-chapter-overview-4"><span class="toc-section-number">5.1</span> Chapter Overview</a></li>
<li><a href="introduction-to-confidence-intervals.html#sampling-distributions" id="toc-sampling-distributions"><span class="toc-section-number">5.2</span> Sampling Distributions</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#sampling-error" id="toc-sampling-error"><span class="toc-section-number">5.2.1</span> Sampling Error</a></li>
<li><a href="introduction-to-confidence-intervals.html#the-central-limit-theorem" id="toc-the-central-limit-theorem"><span class="toc-section-number">5.2.2</span> The Central Limit Theorem</a></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#developing-confidence-intervals" id="toc-developing-confidence-intervals"><span class="toc-section-number">5.3</span> Developing Confidence Intervals</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#interpreting-a-confidence-interval" id="toc-interpreting-a-confidence-interval"><span class="toc-section-number">5.3.1</span> Interpreting a Confidence Interval</a></li>
<li><a href="introduction-to-confidence-intervals.html#exercises-1" id="toc-exercises-1"><span class="toc-section-number">5.3.2</span> Exercises</a></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#other-levels-of-confidence" id="toc-other-levels-of-confidence"><span class="toc-section-number">5.4</span> Other Levels of Confidence</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#r-finding-critical-values" id="toc-r-finding-critical-values">R: Finding Critical Values</a></li>
<li><a href="introduction-to-confidence-intervals.html#breaking-down-a-confidence-interval" id="toc-breaking-down-a-confidence-interval"><span class="toc-section-number">5.4.1</span> Breaking Down a Confidence Interval</a></li>
<li><a href="introduction-to-confidence-intervals.html#confidence-level-precision-and-sample-size" id="toc-confidence-level-precision-and-sample-size"><span class="toc-section-number">5.4.2</span> Confidence Level, Precision, and Sample Size</a></li>
<li><a href="introduction-to-confidence-intervals.html#exercises-2" id="toc-exercises-2"><span class="toc-section-number">5.4.3</span> Exercises</a></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#confidence-intervals-for-a-mean" id="toc-confidence-intervals-for-a-mean"><span class="toc-section-number">5.5</span> Confidence Intervals for a Mean</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#the-t-distribution" id="toc-the-t-distribution"><span class="toc-section-number">5.5.1</span> The T-Distribution</a></li>
<li><a href="introduction-to-confidence-intervals.html#r-t-critical-values" id="toc-r-t-critical-values">R: T Critical Values</a></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#r-confidence-intevals-for-a-mean" id="toc-r-confidence-intevals-for-a-mean">R: Confidence Intevals for a Mean</a></li>
</ul></li>
<li><a href="introduction-to-hypothesis-testing.html#introduction-to-hypothesis-testing" id="toc-introduction-to-hypothesis-testing"><span class="toc-section-number">6</span> Introduction to Hypothesis Testing</a>
<ul>
<li><a href="introduction-to-hypothesis-testing.html#chapter-overview-5" id="toc-chapter-overview-5"><span class="toc-section-number">6.1</span> Chapter Overview</a></li>
<li><a href="introduction-to-hypothesis-testing.html#logic-of-hypothesis-testing" id="toc-logic-of-hypothesis-testing"><span class="toc-section-number">6.2</span> Logic of Hypothesis Testing</a>
<ul>
<li><a href="introduction-to-hypothesis-testing.html#decision-errors" id="toc-decision-errors"><span class="toc-section-number">6.2.1</span> Decision Errors</a></li>
</ul></li>
<li><a href="introduction-to-hypothesis-testing.html#confidence-interval-approach-to-hypothesis-testing" id="toc-confidence-interval-approach-to-hypothesis-testing"><span class="toc-section-number">6.3</span> Confidence Interval Approach to Hypothesis Testing</a></li>
<li><a href="introduction-to-hypothesis-testing.html#critical-value-approach-to-hypothesis-testing" id="toc-critical-value-approach-to-hypothesis-testing"><span class="toc-section-number">6.4</span> Critical Value Approach to Hypothesis Testing</a>
<ul>
<li><a href="introduction-to-hypothesis-testing.html#test-statistics" id="toc-test-statistics"><span class="toc-section-number">6.4.1</span> Test statistics</a></li>
</ul></li>
<li><a href="introduction-to-hypothesis-testing.html#p-value-approach-to-hypothesis-testing" id="toc-p-value-approach-to-hypothesis-testing"><span class="toc-section-number">6.5</span> P-Value Approach to Hypothesis Testing</a>
<ul>
<li><a href="introduction-to-hypothesis-testing.html#p-values" id="toc-p-values"><span class="toc-section-number">6.5.1</span> P-Values</a></li>
</ul></li>
<li><a href="introduction-to-hypothesis-testing.html#r-hypothesis-tests-for-a-mean" id="toc-r-hypothesis-tests-for-a-mean">R: Hypothesis Tests for a Mean</a></li>
</ul></li>
<li><a href="inference-for-a-proportion.html#inference-for-a-proportion" id="toc-inference-for-a-proportion"><span class="toc-section-number">7</span> Inference for a Proportion</a>
<ul>
<li><a href="inference-for-a-proportion.html#chapter-overview-6" id="toc-chapter-overview-6"><span class="toc-section-number">7.1</span> Chapter Overview</a></li>
<li><a href="inference-for-a-proportion.html#confidence-intervals-for-a-proportion" id="toc-confidence-intervals-for-a-proportion"><span class="toc-section-number">7.2</span> Confidence Intervals for a Proportion</a></li>
<li><a href="inference-for-a-proportion.html#hypothesis-tests-for-a-proportion" id="toc-hypothesis-tests-for-a-proportion"><span class="toc-section-number">7.3</span> Hypothesis Tests for a Proportion</a>
<ul>
<li><a href="inference-for-a-proportion.html#confidence-interval-approach" id="toc-confidence-interval-approach"><span class="toc-section-number">7.3.1</span> Confidence Interval Approach</a></li>
<li><a href="inference-for-a-proportion.html#critical-value-approach" id="toc-critical-value-approach"><span class="toc-section-number">7.3.2</span> Critical Value Approach</a></li>
<li><a href="inference-for-a-proportion.html#p-value-approach" id="toc-p-value-approach"><span class="toc-section-number">7.3.3</span> P-Value Approach</a></li>
</ul></li>
<li><a href="inference-for-a-proportion.html#r-hypothesis-tests-for-a-proportion" id="toc-r-hypothesis-tests-for-a-proportion">R: Hypothesis Tests for a Proportion</a></li>
</ul></li>
<li><a href="inference-comparing-parameters.html#inference-comparing-parameters" id="toc-inference-comparing-parameters"><span class="toc-section-number">8</span> Inference: Comparing Parameters</a>
<ul>
<li><a href="inference-comparing-parameters.html#chapter-overview-7" id="toc-chapter-overview-7"><span class="toc-section-number">8.1</span> Chapter Overview</a></li>
<li><a href="inference-comparing-parameters.html#hypothesis-tests-for-two-proportions" id="toc-hypothesis-tests-for-two-proportions"><span class="toc-section-number">8.2</span> Hypothesis Tests for Two Proportions</a>
<ul>
<li><a href="inference-comparing-parameters.html#confidence-intervals-for-two-proportions" id="toc-confidence-intervals-for-two-proportions"><span class="toc-section-number">8.2.1</span> Confidence Intervals for Two Proportions</a></li>
<li><a href="inference-comparing-parameters.html#critical-values-test-statistics-and-p-values" id="toc-critical-values-test-statistics-and-p-values"><span class="toc-section-number">8.2.2</span> Critical Values, Test Statistics, and P-Values</a></li>
<li><a href="inference-comparing-parameters.html#r-hypothesis-tests-for-two-proportions" id="toc-r-hypothesis-tests-for-two-proportions">R: Hypothesis Tests for Two Proportions</a></li>
</ul></li>
<li><a href="inference-comparing-parameters.html#hypothesis-tests-for-two-means" id="toc-hypothesis-tests-for-two-means"><span class="toc-section-number">8.3</span> Hypothesis Tests for Two Means</a>
<ul>
<li><a href="inference-comparing-parameters.html#paired-samples" id="toc-paired-samples"><span class="toc-section-number">8.3.1</span> Paired Samples</a></li>
<li><a href="inference-comparing-parameters.html#independent-samples" id="toc-independent-samples"><span class="toc-section-number">8.3.2</span> Independent Samples</a></li>
<li><a href="inference-comparing-parameters.html#r-hypothesis-tests-for-two-means" id="toc-r-hypothesis-tests-for-two-means">R: Hypothesis Tests for Two Means</a></li>
</ul></li>
</ul></li>
<li><a href="chi-square-tests.html#chi-square-tests" id="toc-chi-square-tests"><span class="toc-section-number">9</span> Chi-Square Tests</a>
<ul>
<li><a href="chi-square-tests.html#chapter-overview-8" id="toc-chapter-overview-8"><span class="toc-section-number">9.1</span> Chapter Overview</a></li>
<li><a href="chi-square-tests.html#inference-for-a-population-variance" id="toc-inference-for-a-population-variance"><span class="toc-section-number">9.2</span> Inference for a Population Variance</a>
<ul>
<li><a href="chi-square-tests.html#the-chi-square-distribution" id="toc-the-chi-square-distribution"><span class="toc-section-number">9.2.1</span> The Chi-Square Distribution</a></li>
</ul></li>
<li><a href="chi-square-tests.html#the-ratio-of-two-variances" id="toc-the-ratio-of-two-variances"><span class="toc-section-number">9.3</span> The Ratio of Two Variances</a></li>
<li><a href="chi-square-tests.html#goodness-of-fit" id="toc-goodness-of-fit"><span class="toc-section-number">9.4</span> Goodness of Fit</a></li>
<li><a href="chi-square-tests.html#contingency-tables" id="toc-contingency-tables"><span class="toc-section-number">9.5</span> Contingency Tables</a></li>
</ul></li>
<li><a href="anova.html#anova" id="toc-anova"><span class="toc-section-number">10</span> ANOVA</a>
<ul>
<li><a href="anova.html#chapter-overview-9" id="toc-chapter-overview-9"><span class="toc-section-number">10.1</span> Chapter Overview</a></li>
<li><a href="anova.html#what-is-the-analysis-of-variance-anova" id="toc-what-is-the-analysis-of-variance-anova"><span class="toc-section-number">10.2</span> What is the Analysis of Variance (ANOVA)</a></li>
<li><a href="anova.html#the-f-distribution" id="toc-the-f-distribution"><span class="toc-section-number">10.3</span> The F-Distribution</a></li>
<li><a href="anova.html#multiple-comparisons-and-type-i-error-rate" id="toc-multiple-comparisons-and-type-i-error-rate"><span class="toc-section-number">10.4</span> Multiple Comparisons and Type I Error Rate</a></li>
</ul></li>
<li><a href="regression-and-correlation.html#regression-and-correlation" id="toc-regression-and-correlation"><span class="toc-section-number">11</span> Regression and Correlation</a>
<ul>
<li><a href="regression-and-correlation.html#chapter-overview-10" id="toc-chapter-overview-10"><span class="toc-section-number">11.1</span> Chapter Overview</a></li>
<li><a href="regression-and-correlation.html#linear-equations" id="toc-linear-equations"><span class="toc-section-number">11.2</span> Linear Equations</a></li>
<li><a href="regression-and-correlation.html#correlation" id="toc-correlation"><span class="toc-section-number">11.3</span> Correlation</a></li>
<li><a href="regression-and-correlation.html#finding-a-regression-line" id="toc-finding-a-regression-line"><span class="toc-section-number">11.4</span> Finding a Regression Line</a>
<ul>
<li><a href="regression-and-correlation.html#coefficient-of-determination" id="toc-coefficient-of-determination"><span class="toc-section-number">11.4.1</span> Coefficient of Determination</a></li>
</ul></li>
</ul></li>
<li><a href="appendices.html#appendices" id="toc-appendices">Appendices</a>
<ul>
<li><a href="appendices.html#appendix-a-important-links-and-additional-resources" id="toc-appendix-a-important-links-and-additional-resources">Appendix A: Important Links and Additional Resources</a>
<ul>
<li><a href="appendices.html#applets" id="toc-applets">Applets</a></li>
<li><a href="appendices.html#run-r-online" id="toc-run-r-online">Run R Online</a></li>
</ul></li>
<li><a href="appendices.html#appendix-b-average-deviance" id="toc-appendix-b-average-deviance">Appendix B: Average Deviance</a></li>
<li><a href="appendices.html#appendix-c-deriving-a-confidence-interval" id="toc-appendix-c-deriving-a-confidence-interval">Appendix C: Deriving a Confidence Interval</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference-comparing-parameters" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Inference: Comparing Parameters<a href="inference-comparing-parameters.html#inference-comparing-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="chapter-overview-7" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Chapter Overview<a href="inference-comparing-parameters.html#chapter-overview-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we extend the concepts from Chapter 6 to answer questions like âis there a difference between these means?â We will also consider hypothesis tests for whether a sample represents the population or closely matches a particular distribution.</p>
<p><strong>Chapter Learning Outcomes/Objectives</strong></p>
<ol style="list-style-type: decimal">
<li>Perform and interpret inference for
<ol style="list-style-type: lower-alpha">
<li>the difference of two proportions.</li>
<li>paired data and two sample means.</li>
</ol></li>
</ol>
<p><strong>R Objectives</strong></p>
<ol style="list-style-type: decimal">
<li>Generate hypothesis tests for the difference of two proportions.</li>
<li>Generate hypothesis tests for the difference of two means.</li>
<li>Interpret R output for tests of two proportions and two means.</li>
</ol>
<p>This chapterâs outcomes correspond to course outcomes (6) apply statistical inference techniques of parameter estimation such as point estimation and confidence interval estimation and (7) apply techniques of testing various statistical hypotheses concerning population parameters.</p>
</div>
<div id="hypothesis-tests-for-two-proportions" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Hypothesis Tests for Two Proportions<a href="inference-comparing-parameters.html#hypothesis-tests-for-two-proportions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sometimes, we might like to <em>compare</em> two proportions. We do this by looking at their <em>difference</em>: <span class="math inline">\(p_1 - p_2\)</span>. This is going to be fairly similar to the tests we used for a single proportion. Let <span class="math inline">\(n_1\)</span> be the sample size for the first group and <span class="math inline">\(p_1\)</span> the proportion for the first group. Similarly, let <span class="math inline">\(n_2\)</span> be the sample size for the second group and <span class="math inline">\(p_2\)</span> the proportion for the second group.</p>
<p>Conditions:</p>
<ol style="list-style-type: decimal">
<li>Independence within and between groups (generally satisfied if the data are from random samples or a randomized experiment).</li>
<li>We need <span class="math inline">\(n_1p_1 &gt; 10\)</span> and <span class="math inline">\(n_1(1-p_1)&gt;10\)</span> <strong>and</strong> <span class="math inline">\(n_2p_2 &gt; 10\)</span> and <span class="math inline">\(n_2(1-p_2)&gt;10\)</span></li>
</ol>
<p>If these conditions are satisfied, the standard error is <span class="math display">\[\sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}\]</span> and we can calculate confidence intervals and perform hypothesis tests on <span class="math inline">\(p_1 - p_2\)</span>.</p>
<div id="confidence-intervals-for-two-proportions" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Confidence Intervals for Two Proportions<a href="inference-comparing-parameters.html#confidence-intervals-for-two-proportions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for <span class="math inline">\(p_1-p_2\)</span> is</p>
<p><span class="math display">\[\hat{p_1} - \hat{p_2} \pm z_{\alpha/2} \times \sqrt{\frac{\hat{p_1}(1-\hat{p_1})}{n_1} + \frac{\hat{p_2}(1-\hat{p_2})}{n_2}}\]</span></p>
</div>
<div id="critical-values-test-statistics-and-p-values" class="section level3 hasAnchor" number="8.2.2">
<h3><span class="header-section-number">8.2.2</span> Critical Values, Test Statistics, and P-Values<a href="inference-comparing-parameters.html#critical-values-test-statistics-and-p-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Often, we are interested in checking whether <span class="math inline">\(p_1 = p_2\)</span>, which results in a null hypothesis of <span class="math inline">\(H_0: p_1 - p_2 = 0\)</span> (where the null value is zero). In this case, we use a <em>pooled proportion</em> to estimate <span class="math inline">\(p\)</span> in the standard error.</p>
<p>This pooled proportion is calculated as <span class="math display">\[\hat{p}_{\text{pooled}} = \frac{\text{total number of successes}}{\text{total number of cases}} = \frac{\hat{p_1}n_1 + \hat{p_2}n_2}{n_1 + n_2}\]</span>
which makes the standard error in this case
<span class="math display">\[ \text{Standard Error} = \sqrt{\frac{\hat{p}_{\text{pooled}}(1-\hat{p}_{\text{pooled}})}{n_1} + \frac{\hat{p}_{\text{pooled}}(1-\hat{p}_{\text{pooled}})}{n_2}}\]</span></p>
<p>The critical value is <span class="math inline">\(z_{\alpha/2}\)</span>. The test statistic is <span class="math display">\[z = \frac{\hat{p_1}-\hat{p_2}}{\sqrt{\frac{\hat{p}_{\text{pooled}}(1-\hat{p}_{\text{pooled}})}{n_1} + \frac{\hat{p}_{\text{pooled}}(1-\hat{p}_{\text{pooled}})}{n_2}}}\]</span>and the p-value is <span class="math display">\[2P(Z &gt; |z|)\]</span> where <span class="math inline">\(z\)</span> is the test statistic.</p>
<p><strong>Steps:</strong></p>
<ol style="list-style-type: decimal">
<li>State the null and alternative hypotheses.</li>
<li>Determine the significance level <span class="math inline">\(\alpha\)</span>. Check assumptions, <span class="math inline">\(n_1p_1 &gt; 10\)</span> and <span class="math inline">\(n_1(1-p_1)&gt;10\)</span> <strong>and</strong> <span class="math inline">\(n_2p_2 &gt; 10\)</span> and <span class="math inline">\(n_2(1-p_2)&gt;10\)</span>.</li>
<li>Compute the value of the test statistic.</li>
<li>Determine the critical value or p-value.</li>
<li>For the <em>critical value approach</em>: If the test statistic is in the rejection region, reject the null hypothesis. For the <em>p-value approach</em>: If <span class="math inline">\(\text{p-value} &lt; \alpha\)</span>, reject the null hypothesis. Otherwise, do not reject.</li>
<li>Interpret results.</li>
</ol>
</div>
<div id="r-hypothesis-tests-for-two-proportions" class="section level3 unnumbered hasAnchor">
<h3>R: Hypothesis Tests for Two Proportions<a href="inference-comparing-parameters.html#r-hypothesis-tests-for-two-proportions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To compare two proportions, we will use the command <code>prop.test</code>. This is similar to <code>binom.test</code>, but the latter command does not allow us to compare two proportions. We will need the following arguments:</p>
<ul>
<li><code>x</code>: a listing of the numbers of successes in each of the two groups. This will take the form <code>x = c(x1, x2)</code>.</li>
<li><code>n</code>: a listing of the numbers of trials for each group. This will take the form <code>n = c(n1, n2)</code>.</li>
<li><code>conf.level</code>: the confidence level (<span class="math inline">\(1-\alpha\)</span>).</li>
</ul>
<p>Note that order matters in <code>c(x1, x2)</code> and <code>c(n1, n2)</code>. Make sure to keep track of which variable you have set as 1 an which as 2. This test also assumes a null hypothesis of <span class="math inline">\(p_1 = p_2\)</span>.</p>
<p>This test has a few behind-the-scenes tweaks relative to what we do by hand. This means that the results might be slightly different than the results you get when running these tests by hand. Thatâs ok!</p>
<p>The <code>sleep</code> dataset in R contains data on two groups (10 in each) of patients given soporific drugs (drugs designed to induce sleep). We want to examine whether the <em>proportion</em> of patients who experienced an increase in hours of sleep differs between the two groups.</p>
<p>I have this set up with two variables, <code>d1</code> and <code>d2</code>, which represent drug 1 and drug 2. Each variable is <span class="math inline">\(1\)</span> if the patient experienced an increase in hours of sleep and <span class="math inline">\(0\)</span> if they did not. Letâs print these out and find out how many successes were in each group.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="inference-comparing-parameters.html#cb73-1" aria-hidden="true" tabindex="-1"></a>d1</span></code></pre></div>
<pre><code>##  [1] 1 0 0 0 0 1 1 1 0 1</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="inference-comparing-parameters.html#cb75-1" aria-hidden="true" tabindex="-1"></a>d2</span></code></pre></div>
<pre><code>##  [1] 1 1 1 1 0 1 1 1 1 1</code></pre>
<p>We can find the total number of successes for each by summing the values in each variable. Letâs do that in R using the <code>sum</code> command:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="inference-comparing-parameters.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(d1)</span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="inference-comparing-parameters.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(d2)</span></code></pre></div>
<pre><code>## [1] 9</code></pre>
<p>So the numbers of successes are <span class="math inline">\(x_1 = 5\)</span> and <span class="math inline">\(x_2 = 9\)</span> for group sizes <span class="math inline">\(n_1 = n_2 = 10\)</span>. For the <code>prop.test</code> command, this will look like <code>x = c(5, 9)</code> and <code>n = c(10,10)</code>. We will use an <span class="math inline">\(\alpha=0.1\)</span> level of significance. Then</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="inference-comparing-parameters.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop.test</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">9</span>), <span class="at">n =</span> <span class="fu">c</span>(<span class="dv">10</span>,<span class="dv">10</span>), <span class="at">conf.level =</span> <span class="fl">0.9</span>)</span></code></pre></div>
<pre><code>## 
##  2-sample test for equality of proportions with continuity correction
## 
## data:  c(5, 9) out of c(10, 10)
## X-squared = 2.1429, df = 1, p-value = 0.1432
## alternative hypothesis: two.sided
## 90 percent confidence interval:
##  -0.803296023  0.003296023
## sample estimates:
## prop 1 prop 2 
##    0.5    0.9</code></pre>
<p>The output of this test is (top to bottom)</p>
<ul>
<li>The data provided in the input.</li>
<li>A test statistic and degrees of freedom (these are part of the behind-the-scenes tweaks and you can ignore them!) along with a p-value.</li>
<li>When a hypothesis test says âtwo sidedâ that means the null hypothesis represents the ânot equalâ condition that we work with.</li>
<li>The requested confidence interval.</li>
<li>The sample proportions.</li>
</ul>
<p>Although the sample proportions appear to be different, the sample sizes are very small! Therefore it is unsurprising that the data provide insufficient evidence to conclude that the drugs differ in their ability to increase hours slept (<span class="math inline">\(p=0.143\)</span> and the confidence interval includes <span class="math inline">\(0\)</span>).</p>
</div>
</div>
<div id="hypothesis-tests-for-two-means" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Hypothesis Tests for Two Means<a href="inference-comparing-parameters.html#hypothesis-tests-for-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>What if we wanted to compare two means? We begin by discussing paired samples. This will feel very familiar, since itâs essentially the same as hypothesis testing for a single mean. Then we will move on to independent samples, which will require a couple of adjustments.</p>
<div id="paired-samples" class="section level3 hasAnchor" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Paired Samples<a href="inference-comparing-parameters.html#paired-samples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sometimes there is a special correspondence between two sets of observations. We say that two sets of observations are <strong>paired</strong> if each observation has a natural connection with exactly one observation in the other data set. Consider the following data from 30 students given a pre- and post-test on a course concept:</p>
<table>
<thead>
<tr class="header">
<th align="center">Student</th>
<th align="center">Pre-Test</th>
<th align="center">Post-Test</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">52</td>
<td align="center">70</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">71</td>
<td align="center">98</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">13</td>
<td align="center">65</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\dots\)</span></td>
<td align="center"><span class="math inline">\(\dots\)</span></td>
<td align="center"><span class="math inline">\(\dots\)</span></td>
</tr>
<tr class="odd">
<td align="center">30</td>
<td align="center">48</td>
<td align="center">81</td>
</tr>
</tbody>
</table>
<p>The natural connection between âpre-testâ and âpost-testâ is the student who took each test! Often, paired data will involve similar measures taken on the <em>same item or individual</em>. We <em>pair</em> these data because we want to compare two means, but we also want to account for the pairing.</p>
<p>Why? Consider: If a student got a 13% on the pre-test, I would love to see them get a 60% on the post-test - thatâs a huge improvement! But if a student got an 82% on the pre-test, I would <em>not</em> like to see them get a 60% on the post-test. Pairing the data lets us account for this connection.</p>
<p>So what do we do with paired data? Fortunately, this part is easy! We start by taking the difference between the two sets of observations. In the pre- and post-test example, I will take the pre-test score and subtract the post-test score:</p>
<table>
<thead>
<tr class="header">
<th align="center">Student</th>
<th align="center">Pre-Test</th>
<th align="center">Post-Test</th>
<th align="center"><strong>Difference</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">52</td>
<td align="center">70</td>
<td align="center"><strong>18</strong></td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">71</td>
<td align="center">98</td>
<td align="center"><strong>27</strong></td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">13</td>
<td align="center">65</td>
<td align="center"><strong>52</strong></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\dots\)</span></td>
<td align="center"><span class="math inline">\(\dots\)</span></td>
<td align="center"><span class="math inline">\(\dots\)</span></td>
<td align="center"><span class="math inline">\(\dots\)</span></td>
</tr>
<tr class="odd">
<td align="center">30</td>
<td align="center">48</td>
<td align="center">81</td>
<td align="center"><strong>33</strong></td>
</tr>
</tbody>
</table>
<p>Then, we do a test of a <em>single mean</em> on the differences where</p>
<ul>
<li><span class="math inline">\(H_0: \mu_{\text{d}} = 0\)</span></li>
<li><span class="math inline">\(H_A: \mu_{\text{d}} \ne 0\)</span></li>
</ul>
<p>Note that the subscript âdâ denotes âdifferenceâ. We will use the exact same test(s) as in the previous sections:</p>
<ul>
<li><p><strong>Large Sample Setting</strong>: <span class="math inline">\(\mu_{\text{d}}\)</span> is target parameter, <span class="math inline">\(n_{\text{d}} \ge 30\)</span>, <span class="math display">\[z = \frac{\bar{x}_{\text{d}}}{s_{\text{d}}/\sqrt{n_{\text{d}}}}\]</span> and the p-value is <span class="math display">\[2P(Z &gt; |z|)\]</span> where <span class="math inline">\(z\)</span> is the test statistic.</p></li>
<li><p><strong>Small Sample Setting</strong>: <span class="math inline">\(\mu_{\text{d}}\)</span> is target parameter, <span class="math inline">\(n_{\text{d}} &lt; 30\)</span>, <span class="math display">\[t = \frac{\bar{x}_{\text{d}}}{s_{\text{d}}/\sqrt{n_{\text{d}}}}\]</span> and the p-value is <span class="math display">\[2P(t_{df} &gt; |t|)\]</span> where <span class="math inline">\(t\)</span> is the test statistic.</p></li>
</ul>
<p>Here, <span class="math inline">\(n_{\text{d}}\)</span> is the number of pairs.</p>
<p>Steps:</p>
<ol style="list-style-type: decimal">
<li>State the null and alternative hypotheses.</li>
<li>Determine the significance level <span class="math inline">\(\alpha\)</span>. Check assumptions (decide which setting to use).</li>
<li>Compute the value of the test statistic.</li>
<li>Determine the critical values or p-value.</li>
<li>For the <em>critical value approach</em>: If the test statistic is in the rejection region, reject the null hypothesis. For the <em>p-value approach</em>: If <span class="math inline">\(\text{p-value} &lt; \alpha\)</span>, reject the null hypothesis. Otherwise, do not reject.</li>
<li>Interpret results.</li>
</ol>
</div>
<div id="independent-samples" class="section level3 hasAnchor" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Independent Samples<a href="inference-comparing-parameters.html#independent-samples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In <strong>independent samples</strong>, the sample from one population does not impact the sample from the other population. In short, we take two <em>separate samples</em> and compare them.</p>
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2 \quad \rightarrow \quad H_0: \mu_1 - \mu_2 = 0\)</span></li>
<li><span class="math inline">\(H_A: \mu_1 \ne \mu_2 \quad \rightarrow \quad H_A: \mu_1 - \mu_2 \ne 0\)</span></li>
</ul>
<p>If we use <span class="math inline">\(\bar{x}\)</span> to estimate <span class="math inline">\(\mu\)</span>, intuitively we might use <span class="math inline">\(\bar{x}_1-\bar{x}_2\)</span> to estimate <span class="math inline">\(\mu_1 - \mu_2\)</span>. To do this, we need to know something about the sampling distribution of <span class="math inline">\(\bar{x}_1-\bar{x}_2\)</span>.</p>
<p>Consider: if <span class="math inline">\(X_1\)</span> is Normal(<span class="math inline">\(\mu_1\)</span>, <span class="math inline">\(\sigma_1\)</span>) and <span class="math inline">\(X_2\)</span> is Normal(<span class="math inline">\(\mu_2\)</span>,<span class="math inline">\(\sigma_2\)</span>) with <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span> are known, then for independent samples of size <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span>,</p>
<ul>
<li><span class="math inline">\(\bar{X}_1-\bar{X}_2\)</span> is Normal(<span class="math inline">\(\mu_{\bar{X}_1-\bar{X}_2}\)</span>, <span class="math inline">\(\sigma_{\bar{X}_1-\bar{X}_2}\)</span>).</li>
<li><span class="math inline">\(\mu_{\bar{X}_1-\bar{X}_2} = \mu_1 - \mu_2\)</span></li>
<li><span class="math inline">\(\sigma_{\bar{X}_1-\bar{X}_2} = \sigma_1 - \sigma_2\)</span></li>
</ul>
<p>so then <span class="math display">\[Z = \frac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{\sigma_1/n_1 - \sigma_2/n_2}}\]</span> has a standard normal distribution. But, as we mentioned earlier, we rarely work in that setting where the population standard deviation is known. Instead, we will use <span class="math inline">\(s_1\)</span> and <span class="math inline">\(s_2\)</span> to estimate <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span>. For independent samples of size <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span>, <span class="math display">\[t = \frac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{s_1/n_1 - s_2/n_2}}\]</span> has a t-distribution with degrees of freedom <span class="math display">\[\Delta = \frac{[(s_1^2/n_1) + (s_2^2/n_2)]^2}{\frac{(s_1^2/n_1)^2}{n_1-1} + \frac{(s_2^2/n_2)^2}{n_2-1}}\]</span> rounded <em>down</em> to the nearest whole number. (Note that <span class="math inline">\(\Delta\)</span> is the uppercase Greek letter, âdeltaâ.) If <span class="math inline">\(n_1 = n_2\)</span>, this simplifies to <span class="math display">\[\Delta = (n-1)\left(\frac{(s_1^2 + s_2^2)^2}{s_1^4 + s_2^4}\right)\]</span></p>
<p><strong>Tip:</strong> Generally, people do not calculate <span class="math inline">\(\Delta\)</span> by hand. Instead, we use a computer to do these kinds of tests.</p>
<center>
<font size='4'><strong>The Two-Sample T-Test</strong>
</center>
<p></font></p>
<p>Assumptions:</p>
<ul>
<li>Simple random samples.</li>
<li>Independent samples.</li>
<li>Normal populations or large (<span class="math inline">\(n \ge 30\)</span>) samples.</li>
</ul>
<p><strong>Steps for Critical Value Approach</strong>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(H_0: \mu_1 - \mu_2 = 0\)</span> and <span class="math inline">\(H_A: \mu_1 - \mu_2 \ne 0\)</span></li>
<li>Check assumptions; select the significance level <span class="math inline">\(\alpha\)</span>.</li>
<li>Compute the test statistic <span class="math display">\[t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{s_1/n_1 - s_2/n_2}}\]</span> Note that we assume under the null hypothesis that <span class="math inline">\(\mu_1 - \mu_2 = 0\)</span>, which is why we replace this quantity with <span class="math inline">\(0\)</span> in the test statistic.</li>
<li>The critical value is <span class="math inline">\(\pm t_{df, \alpha/2}\)</span> with <span class="math inline">\(df = \Delta\)</span>.</li>
<li>If the test statistic falls in the rejection region, reject the null hypothesis.</li>
<li>Interpret in the context of the problem.</li>
</ol>
<p><strong>Steps for P-Value Approach</strong>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(H_0: \mu_1 - \mu_2 = 0\)</span> and <span class="math inline">\(H_A: \mu_1 - \mu_2 \ne 0\)</span></li>
<li>Check assumptions; select the significance level <span class="math inline">\(\alpha\)</span>.</li>
<li>Compute the test statistic <span class="math display">\[t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{s_1/n_1 - s_2/n_2}}\]</span> Note that we assume under the null hypothesis that <span class="math inline">\(\mu_1 - \mu_2 = 0\)</span>, which is why we replace this quantity with <span class="math inline">\(0\)</span> in the test statistic.</li>
<li>The p-value is <span class="math inline">\(2P(t_{df} &gt; |t|)\)</span> with <span class="math inline">\(df = \Delta\)</span>.</li>
<li>If <span class="math inline">\(\text{p-value}&lt;\alpha\)</span>, reject the null hypothesis.</li>
<li>Interpret in the context of the problem.</li>
</ol>
<p>Notice that the only difference between the critical value and p-value approaches are steps 4 and 5.</p>
<blockquote>
<p><em>Example</em>: Researchers wanted to detemine whether a dymanic or static approach would impact the time needed to complete neurosurgeries. The experiment resulted in the following data from simple random samples of patients:</p>
<table>
<thead>
<tr class="header">
<th align="center">Dynamic</th>
<th align="center">Static</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\bar{x}_1 = 394.6\)</span></td>
<td align="center"><span class="math inline">\(\bar{x}_2 = 468.3\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(s_1 = 84.7\)</span></td>
<td align="center"><span class="math inline">\(s_2 = 38.2\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(n_1 = 14\)</span></td>
<td align="center"><span class="math inline">\(n_2 = 6\)</span></td>
</tr>
</tbody>
</table>
<p>Times are measured in minutes. Assume <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are reasonably normal.</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(H_0: \mu_1 = \mu_2\)</span> and <span class="math inline">\(H_A: \mu_1\ne\mu_2\)</span></li>
<li>Let <span class="math inline">\(\alpha=0.05\)</span> (this will be our default when a significance level is not given)
<ul>
<li>We are told these are simple random samples.</li>
<li>Thereâs no reason that time for a neurosurgery with the dynamic system would impact time for the static system (or vice versa), so itâs reasonable to assume these samples are independent.</li>
<li>We are told to assume that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are reasonably normal.</li>
</ul></li>
<li>The test statistic is <span class="math display">\[t = \frac{394.6-468.3}{84.7^2/14 + 38.2^2/6} = -2.681\]</span></li>
<li>Then <span class="math display">\[df = \Delta = \frac{(84.7^2/14) + (38.2^2/6)^2}{\frac{(84.7^2/14)^2}{14-1} + \frac{(38.2^2/6)^2}{6-1}} = 17\]</span> when rounded down. The critical value is <span class="math display">\[t_{17, 0.025} = 2.110\]</span> and the p-value is <span class="math display">\[2P(t_{17}&gt;|-2.681|)=2(0.0079)=0.0158\]</span></li>
<li>For the critical value approach,</li>
</ol>
</blockquote>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
<blockquote>
<p>Since the test statistic is in the rejection region, we reject the null hypothesis. For the p-value approach, since <span class="math inline">\(\text{p-value}=0.158 &lt; \alpha =0.05\)</span>, reject the null hypothesis.</p>
<ol start="6" style="list-style-type: decimal">
<li>At the 0.05 level of significance, the data provide sufficient evidence to conclude that the mean time for the dynamic system is less than the mean time for the static system.</li>
</ol>
</blockquote>
<p>We can also construct a <strong><span class="math inline">\((1-\alpha)100\%\)</span> confidence interval</strong> for the difference of the two population means: <span class="math display">\[(\bar{x}_1-\bar{x}_2) \pm t_{df, \alpha/2}\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}\]</span> which we interpret as we interpret other confidence intervals, including in our interpretation that we are now considering the <strong>difference of two means</strong>.</p>
</div>
<div id="r-hypothesis-tests-for-two-means" class="section level3 unnumbered hasAnchor">
<h3>R: Hypothesis Tests for Two Means<a href="inference-comparing-parameters.html#r-hypothesis-tests-for-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The math has only gotten more cumbersome! Letâs use R to quickly run these types of tests without having to do any calculations by hand.</p>
<p>There is data built into R that shows the effect of Vitamin C on tooth growth in guinea pigs through (A) ascorbic acid or (B) orange juice. (Each guinea pig was randomly assigned to either ascorbic acid <em>or</em> orange juice.) We want to compare the ascorbic acid group to the orange juice group to see if one has more tooth growth than the other. This is currently in a data set called <code>teeth</code>, which contains two variables: <code>aa</code>, the tooth length for guinea pigs in the ascorbic acid group and <code>oj</code> the tooth length for the orange juice group.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="inference-comparing-parameters.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(teeth)</span></code></pre></div>
<p>To run a two-sample test comparing means in R, we continue to use the command <code>t.test</code>. The arguments we need in this case are:</p>
<ul>
<li><code>x</code>: the first variable.</li>
<li><code>y</code>: the other variable.</li>
<li><code>mu</code>: the null value, usually <span class="math inline">\(\mu_1-\mu_2=0\)</span>.</li>
<li><code>paired</code>: set this equal to <code>TRUE</code> for paired t tests; set it equal to <code>FALSE</code> for independent samples.</li>
<li><code>conf.level</code>: the desired confidence level (<span class="math inline">\(1-\alpha\)</span>).</li>
</ul>
<p>In this case, we are interested in variables <code>x = aa</code> and <code>y = oj</code>. The null value is <code>mu = 0</code>. Guinea pigs were randomly assigned to each treatment group, so these are independent samples and <code>paired = FALSE</code>. Finally, we will go ahead and test this at a 0.05 level of significance, so <code>conf.level = 0.95</code>. Putting that all together, the R command looks like</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="inference-comparing-parameters.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> aa, <span class="at">y =</span> oj, <span class="at">mu =</span> <span class="dv">0</span>, <span class="at">paired =</span> <span class="cn">FALSE</span>, <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  aa and oj
## t = -1.9153, df = 55.309, p-value = 0.06063
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -7.5710156  0.1710156
## sample estimates:
## mean of x mean of y 
##  16.96333  20.66333</code></pre>
<p>The R output shows (top to bottom)</p>
<ul>
<li>variables entered.</li>
<li>the test statistic, degrees of freedom, and p-value.</li>
<li>the alternative hypothesis.</li>
<li>a confidence interval for the difference of the two means.</li>
<li>sample means for each variable.</li>
</ul>
<p>Based on the output, at the 0.05 level of significance, the data provide insufficient evidence to conclude that the mean tooth length for guinea pigs receiving ascorbic acid differs from the guinea pigs receiving orange juice (<span class="math inline">\(p = 0.061\)</span> and the confidence interval includes 0).</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inference-for-a-proportion.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chi-square-tests.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IntroStats.pdf", "IntroStats.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
