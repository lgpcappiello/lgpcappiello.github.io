<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Introduction to Inference | Introduction to Statistics</title>
  <meta name="description" content="Chapter 5 Introduction to Inference | Introduction to Statistics." />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Introduction to Inference | Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 5 Introduction to Inference | Introduction to Statistics." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Introduction to Inference | Introduction to Statistics" />
  
  <meta name="twitter:description" content="Chapter 5 Introduction to Inference | Introduction to Statistics." />
  

<meta name="author" content="Dr. Lauren Cappiello" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="random-variables.html"/>
<link rel="next" href="introduction-to-hypothesis-testing.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>For the Instructor</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-data.html"><a href="introduction-to-data.html"><i class="fa fa-check"></i><b>1</b> Introduction to Data</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#module-overview"><i class="fa fa-check"></i><b>1.1</b> Module Overview</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#statistics-terminology"><i class="fa fa-check"></i><b>1.2</b> Statistics Terminology</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-data.html"><a href="introduction-to-data.html#section-exercises"><i class="fa fa-check"></i>Section Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-data.html"><a href="introduction-to-data.html#sampling-and-design"><i class="fa fa-check"></i><b>1.3</b> Sampling and Design</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#statistical-sampling"><i class="fa fa-check"></i><b>1.3.1</b> Statistical Sampling</a></li>
<li class="chapter" data-level="" data-path="introduction-to-data.html"><a href="introduction-to-data.html#r-random-number-generation"><i class="fa fa-check"></i>R: Random Number Generation</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#experimental-design"><i class="fa fa-check"></i><b>1.3.2</b> Experimental Design</a></li>
<li class="chapter" data-level="" data-path="introduction-to-data.html"><a href="introduction-to-data.html#section-exercises-1"><i class="fa fa-check"></i>Section Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-data.html"><a href="introduction-to-data.html#frequency-distributions"><i class="fa fa-check"></i><b>1.4</b> Frequency Distributions</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-to-data.html"><a href="introduction-to-data.html#qualitative-variables"><i class="fa fa-check"></i><b>1.4.1</b> Qualitative Variables</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-to-data.html"><a href="introduction-to-data.html#quantitative-variables"><i class="fa fa-check"></i><b>1.4.2</b> Quantitative Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="descriptive-measures.html"><a href="descriptive-measures.html"><i class="fa fa-check"></i><b>2</b> Descriptive Measures</a>
<ul>
<li class="chapter" data-level="2.1" data-path="descriptive-measures.html"><a href="descriptive-measures.html#chapter-overview"><i class="fa fa-check"></i><b>2.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="2.2" data-path="descriptive-measures.html"><a href="descriptive-measures.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>2.2</b> Measures of Central Tendency</a></li>
<li class="chapter" data-level="2.3" data-path="descriptive-measures.html"><a href="descriptive-measures.html#measures-of-variability"><i class="fa fa-check"></i><b>2.3</b> Measures of Variability</a></li>
<li class="chapter" data-level="2.4" data-path="descriptive-measures.html"><a href="descriptive-measures.html#measures-of-position"><i class="fa fa-check"></i><b>2.4</b> Measures of Position</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="descriptive-measures.html"><a href="descriptive-measures.html#box-plots"><i class="fa fa-check"></i><b>2.4.1</b> Box Plots</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="descriptive-measures.html"><a href="descriptive-measures.html#descriptive-measures-for-populations"><i class="fa fa-check"></i><b>2.5</b> Descriptive Measures for Populations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability-concepts.html"><a href="probability-concepts.html"><i class="fa fa-check"></i><b>3</b> Probability Concepts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability-concepts.html"><a href="probability-concepts.html#chapter-overview-1"><i class="fa fa-check"></i><b>3.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="3.2" data-path="probability-concepts.html"><a href="probability-concepts.html#experiments-sample-spaces-and-events"><i class="fa fa-check"></i><b>3.2</b> Experiments, Sample Spaces, and Events</a></li>
<li class="chapter" data-level="3.3" data-path="probability-concepts.html"><a href="probability-concepts.html#probability-distributions"><i class="fa fa-check"></i><b>3.3</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="probability-concepts.html"><a href="probability-concepts.html#venn-diagrams"><i class="fa fa-check"></i><b>3.3.1</b> Venn Diagrams</a></li>
<li class="chapter" data-level="3.3.2" data-path="probability-concepts.html"><a href="probability-concepts.html#probability-axioms"><i class="fa fa-check"></i><b>3.3.2</b> Probability Axioms</a></li>
<li class="chapter" data-level="" data-path="probability-concepts.html"><a href="probability-concepts.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="probability-concepts.html"><a href="probability-concepts.html#rules-of-probability"><i class="fa fa-check"></i><b>3.4</b> Rules of Probability</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="probability-concepts.html"><a href="probability-concepts.html#addition-rules"><i class="fa fa-check"></i><b>3.4.1</b> Addition Rules</a></li>
<li class="chapter" data-level="3.4.2" data-path="probability-concepts.html"><a href="probability-concepts.html#complements"><i class="fa fa-check"></i><b>3.4.2</b> Complements</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="probability-concepts.html"><a href="probability-concepts.html#conditional-probability"><i class="fa fa-check"></i><b>3.5</b> Conditional Probability</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="probability-concepts.html"><a href="probability-concepts.html#multiplication-rules"><i class="fa fa-check"></i><b>3.5.1</b> Multiplication Rules</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>4</b> Random Variables</a>
<ul>
<li class="chapter" data-level="4.1" data-path="random-variables.html"><a href="random-variables.html#chapter-overview-2"><i class="fa fa-check"></i><b>4.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="4.2" data-path="random-variables.html"><a href="random-variables.html#discrete-random-variables"><i class="fa fa-check"></i><b>4.2</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="random-variables.html"><a href="random-variables.html#the-mean-and-standard-deviation"><i class="fa fa-check"></i><b>4.2.1</b> The Mean and Standard Deviation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="random-variables.html"><a href="random-variables.html#the-binomial-distribution"><i class="fa fa-check"></i><b>4.3</b> The Binomial Distribution</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="random-variables.html"><a href="random-variables.html#mean-and-variance"><i class="fa fa-check"></i><b>4.3.1</b> Mean and Variance</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="random-variables.html"><a href="random-variables.html#the-normal-distribution"><i class="fa fa-check"></i><b>4.4</b> The Normal Distribution</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="random-variables.html"><a href="random-variables.html#the-standard-normal-distribution"><i class="fa fa-check"></i><b>4.4.1</b> The Standard Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="random-variables.html"><a href="random-variables.html#area-under-the-standard-normal-curve"><i class="fa fa-check"></i><b>4.5</b> Area Under the Standard Normal Curve</a></li>
<li class="chapter" data-level="4.6" data-path="random-variables.html"><a href="random-variables.html#working-with-normally-distributed-variables"><i class="fa fa-check"></i><b>4.6</b> Working with Normally Distributed Variables</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="random-variables.html"><a href="random-variables.html#normal-distribution-probabilities"><i class="fa fa-check"></i><b>4.6.1</b> Normal Distribution Probabilities</a></li>
<li class="chapter" data-level="4.6.2" data-path="random-variables.html"><a href="random-variables.html#empirical-rule-for-variables"><i class="fa fa-check"></i><b>4.6.2</b> Empirical Rule for Variables</a></li>
<li class="chapter" data-level="4.6.3" data-path="random-variables.html"><a href="random-variables.html#percentiles"><i class="fa fa-check"></i><b>4.6.3</b> Percentiles</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="random-variables.html"><a href="random-variables.html#the-normal-approximation-to-the-binomial-distribution"><i class="fa fa-check"></i><b>4.7</b> The Normal Approximation to the Binomial Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html"><i class="fa fa-check"></i><b>5</b> Introduction to Inference</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#chapter-overview-3"><i class="fa fa-check"></i><b>5.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="5.2" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#sampling-distributions"><i class="fa fa-check"></i><b>5.2</b> Sampling Distributions</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#sampling-error"><i class="fa fa-check"></i><b>5.2.1</b> Sampling Error</a></li>
<li class="chapter" data-level="5.2.2" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#the-sampling-distribution-of-barx"><i class="fa fa-check"></i><b>5.2.2</b> The Sampling Distribution of <span class="math inline">\(\bar{X}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#developing-confidence-intervals"><i class="fa fa-check"></i><b>5.3</b> Developing Confidence Intervals</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#interpreting-a-confidence-interval"><i class="fa fa-check"></i><b>5.3.1</b> Interpreting a Confidence Interval</a></li>
<li class="chapter" data-level="5.3.2" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#exercises-1"><i class="fa fa-check"></i><b>5.3.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#other-levels-of-confidence"><i class="fa fa-check"></i><b>5.4</b> Other Levels of Confidence</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#breaking-down-a-confidence-interval"><i class="fa fa-check"></i><b>5.4.1</b> Breaking Down a Confidence Interval</a></li>
<li class="chapter" data-level="5.4.2" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#confidence-level-precision-and-sample-size"><i class="fa fa-check"></i><b>5.4.2</b> Confidence Level, Precision, and Sample Size</a></li>
<li class="chapter" data-level="5.4.3" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#exercises-2"><i class="fa fa-check"></i><b>5.4.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#confidence-intervals-sigma-unknown"><i class="fa fa-check"></i><b>5.5</b> Confidence Intervals, <span class="math inline">\(\sigma\)</span> Unknown</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#the-t-distribution"><i class="fa fa-check"></i><b>5.5.1</b> The T-Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#confidence-intervals-for-a-proportion"><i class="fa fa-check"></i><b>5.6</b> Confidence Intervals for a Proportion</a></li>
<li class="chapter" data-level="5.7" data-path="introduction-to-inference.html"><a href="introduction-to-inference.html#summary-of-confidence-interval-settings"><i class="fa fa-check"></i><b>5.7</b> Summary of Confidence Interval Settings</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Introduction to Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#chapter-overview-4"><i class="fa fa-check"></i><b>6.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#logic-of-hypothesis-testing"><i class="fa fa-check"></i><b>6.2</b> Logic of Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#decision-errors"><i class="fa fa-check"></i><b>6.2.1</b> Decision Errors</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#confidence-interval-approach-to-hypothesis-testing"><i class="fa fa-check"></i><b>6.3</b> Confidence Interval Approach to Hypothesis Testing</a></li>
<li class="chapter" data-level="6.4" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#critical-value-approach-to-hypothesis-testing"><i class="fa fa-check"></i><b>6.4</b> Critical Value Approach to Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#test-statistics"><i class="fa fa-check"></i><b>6.4.1</b> Test statistics</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#p-value-approach-to-hypothesis-testing"><i class="fa fa-check"></i><b>6.5</b> P-Value Approach to Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="introduction-to-hypothesis-testing.html"><a href="introduction-to-hypothesis-testing.html#p-values"><i class="fa fa-check"></i><b>6.5.1</b> P-Values</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html"><i class="fa fa-check"></i><b>7</b> Inference for a Proportion</a>
<ul>
<li class="chapter" data-level="7.1" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#chapter-overview-5"><i class="fa fa-check"></i><b>7.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="7.2" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#hypothesis-tests-for-a-proportion"><i class="fa fa-check"></i><b>7.2</b> Hypothesis Tests for a Proportion</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#confidence-interval-approach"><i class="fa fa-check"></i><b>7.2.1</b> Confidence Interval Approach</a></li>
<li class="chapter" data-level="7.2.2" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#critical-value-approach"><i class="fa fa-check"></i><b>7.2.2</b> Critical Value Approach</a></li>
<li class="chapter" data-level="7.2.3" data-path="inference-for-a-proportion.html"><a href="inference-for-a-proportion.html#p-value-approach"><i class="fa fa-check"></i><b>7.2.3</b> P-Value Approach</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="inference-comparing-parameters.html"><a href="inference-comparing-parameters.html"><i class="fa fa-check"></i><b>8</b> Inference: Comparing Parameters</a>
<ul>
<li class="chapter" data-level="8.1" data-path="inference-comparing-parameters.html"><a href="inference-comparing-parameters.html#chapter-overview-6"><i class="fa fa-check"></i><b>8.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="8.2" data-path="inference-comparing-parameters.html"><a href="inference-comparing-parameters.html#hypothesis-tests-for-two-proportions"><i class="fa fa-check"></i><b>8.2</b> Hypothesis Tests for Two Proportions</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="inference-comparing-parameters.html"><a href="inference-comparing-parameters.html#confidence-intervals-for-two-proportions"><i class="fa fa-check"></i><b>8.2.1</b> Confidence Intervals for Two Proportions</a></li>
<li class="chapter" data-level="8.2.2" data-path="inference-comparing-parameters.html"><a href="inference-comparing-parameters.html#critical-values-test-statistics-and-p-values"><i class="fa fa-check"></i><b>8.2.2</b> Critical Values, Test Statistics, and P-Values</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="inference-comparing-parameters.html"><a href="inference-comparing-parameters.html#hypothesis-tests-for-two-means"><i class="fa fa-check"></i><b>8.3</b> Hypothesis Tests for Two Means</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="inference-comparing-parameters.html"><a href="inference-comparing-parameters.html#paired-samples"><i class="fa fa-check"></i><b>8.3.1</b> Paired Samples</a></li>
<li class="chapter" data-level="8.3.2" data-path="inference-comparing-parameters.html"><a href="inference-comparing-parameters.html#independent-samples"><i class="fa fa-check"></i><b>8.3.2</b> Independent Samples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chi-square-tests.html"><a href="chi-square-tests.html"><i class="fa fa-check"></i><b>9</b> Chi-Square Tests</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chi-square-tests.html"><a href="chi-square-tests.html#chapter-overview-7"><i class="fa fa-check"></i><b>9.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="9.2" data-path="chi-square-tests.html"><a href="chi-square-tests.html#inference-for-a-population-variance"><i class="fa fa-check"></i><b>9.2</b> Inference for a Population Variance</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="chi-square-tests.html"><a href="chi-square-tests.html#the-chi-square-distribution"><i class="fa fa-check"></i><b>9.2.1</b> The Chi-Square Distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="chi-square-tests.html"><a href="chi-square-tests.html#the-ratio-of-two-variances"><i class="fa fa-check"></i><b>9.3</b> The Ratio of Two Variances</a></li>
<li class="chapter" data-level="9.4" data-path="chi-square-tests.html"><a href="chi-square-tests.html#goodness-of-fit"><i class="fa fa-check"></i><b>9.4</b> Goodness of Fit</a></li>
<li class="chapter" data-level="9.5" data-path="chi-square-tests.html"><a href="chi-square-tests.html#contingency-tables"><i class="fa fa-check"></i><b>9.5</b> Contingency Tables</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>10</b> ANOVA</a>
<ul>
<li class="chapter" data-level="10.1" data-path="anova.html"><a href="anova.html#chapter-overview-8"><i class="fa fa-check"></i><b>10.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="10.2" data-path="anova.html"><a href="anova.html#what-is-the-analysis-of-variance-anova"><i class="fa fa-check"></i><b>10.2</b> What is the Analysis of Variance (ANOVA)</a></li>
<li class="chapter" data-level="10.3" data-path="anova.html"><a href="anova.html#the-f-distribution"><i class="fa fa-check"></i><b>10.3</b> The F-Distribution</a></li>
<li class="chapter" data-level="10.4" data-path="anova.html"><a href="anova.html#multiple-comparisons-and-type-i-error-rate"><i class="fa fa-check"></i><b>10.4</b> Multiple Comparisons and Type I Error Rate</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html"><i class="fa fa-check"></i><b>11</b> Regression and Correlation</a>
<ul>
<li class="chapter" data-level="11.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#chapter-overview-9"><i class="fa fa-check"></i><b>11.1</b> Chapter Overview</a></li>
<li class="chapter" data-level="11.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#linear-equations"><i class="fa fa-check"></i><b>11.2</b> Linear Equations</a></li>
<li class="chapter" data-level="11.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlation"><i class="fa fa-check"></i><b>11.3</b> Correlation</a></li>
<li class="chapter" data-level="11.4" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#finding-a-regression-line"><i class="fa fa-check"></i><b>11.4</b> Finding a Regression Line</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#coefficient-of-determination"><i class="fa fa-check"></i><b>11.4.1</b> Coefficient of Determination</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#appendix-a-important-links-and-additional-resources"><i class="fa fa-check"></i>Appendix A: Important Links and Additional Resources</a>
<ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#applets"><i class="fa fa-check"></i>Applets</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#run-r-online"><i class="fa fa-check"></i>Run R Online</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#appendix-b-average-deviance"><i class="fa fa-check"></i>Appendix B: Average Deviance</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-inference" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Introduction to Inference<a href="introduction-to-inference.html#introduction-to-inference" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="chapter-overview-3" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Chapter Overview<a href="introduction-to-inference.html#chapter-overview-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter will bridge the gap between our discussion on the normal distribution and our first forays into statistical inference. As it turns out, much of the statistical inference we will use relies on the normal distribution and the t-distribution, which we will introduce in this chapter. We begin our study of statistical inference by learning about confidence intervals.</p>
<p><strong>Chapter Learning Objectives/Outcomes</strong></p>
<ol style="list-style-type: decimal">
<li>Find the distribution of a sample mean.</li>
<li>Estimate probabilities for a sample mean.</li>
<li>Calculate and interpret confidence intervals for a population mean.</li>
<li>Use the standard normal and t-distributions to find critical values.</li>
</ol>
<p>This chapter’s outcomes correspond to course outcome (6) apply statistical inference techniques of parameter estimation such as point estimation and confidence interval estimation and (7) apply techniques of testing various statistical hypotheses concerning population parameters.</p>
</div>
<div id="sampling-distributions" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Sampling Distributions<a href="introduction-to-inference.html#sampling-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="sampling-error" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Sampling Error<a href="introduction-to-inference.html#sampling-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We want to use a sample to learn something about a population, but no sample is perfect! <strong>Sampling error</strong> is the error resulting from using a sample to estimate a population characteristic.</p>
<p>If we use a sample mean <span class="math inline">\(\bar{x}\)</span> to estimate <span class="math inline">\(\mu\)</span>, chances are that <span class="math inline">\(\bar{x}\ne\mu\)</span> (they might be close but… they might not be!). We will consider</p>
<ul>
<li>How close <em>is</em> <span class="math inline">\(\bar{x}\)</span> to <span class="math inline">\(\mu\)</span>?</li>
<li>What if we took many samples and calculated <span class="math inline">\(\bar{x}\)</span> many times?
<ul>
<li>How would that relate to <span class="math inline">\(\mu\)</span>?</li>
<li>What would be the distribution of these values?</li>
</ul></li>
</ul>
<p>The distribution of a statistic (across all possible samples of size <span class="math inline">\(n\)</span>) is called the <strong>sampling distribution</strong>. We will focus primarily on the distribution of the sample mean.</p>
<p>For a variable <span class="math inline">\(x\)</span> and given a sample size <span class="math inline">\(n\)</span>, the distribution of <span class="math inline">\(\bar{x}\)</span> is called the <strong>sampling distribution of the sample mean</strong> or the <strong>distribution of <span class="math inline">\(\boldsymbol{\bar{x}}\)</span></strong>.</p>
<blockquote>
<p><em>Example</em>: Suppose our population is the five starting players on a particular basketball team. We are interested in their heights (measures in inches). The full population data is</p>
<table>
<thead>
<tr class="header">
<th align="left">Player</th>
<th align="center">A</th>
<th align="center">B</th>
<th align="center">C</th>
<th align="center">D</th>
<th align="center">E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Height</td>
<td align="center">76</td>
<td align="center">78</td>
<td align="center">79</td>
<td align="center">81</td>
<td align="center">86</td>
</tr>
</tbody>
</table>
<p>The population mean is <span class="math inline">\(\mu=80\)</span>. Consider all possible samples of size <span class="math inline">\(n=2\)</span>:</p>
<table>
<thead>
<tr class="header">
<th align="left">Sample</th>
<th align="center">A,B</th>
<th align="center">A,C</th>
<th align="center">A,D</th>
<th align="center">A,E</th>
<th align="center">B,C</th>
<th align="center">B,D</th>
<th align="center">B,E</th>
<th align="center">C,D</th>
<th align="center">C,E</th>
<th align="center">D,E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\bar{x}\)</span></td>
<td align="center">77</td>
<td align="center">77.5</td>
<td align="center">78.5</td>
<td align="center">81.0</td>
<td align="center">78.5</td>
<td align="center">79.5</td>
<td align="center">82.0</td>
<td align="center">80.0</td>
<td align="center">82.5</td>
<td align="center">83.5</td>
</tr>
</tbody>
</table>
<p>There are 10 possible samples of size 2. Of these samples, 10% have means exactly equal to <span class="math inline">\(\mu\)</span> (for a <em>random</em> sample of size 2, you’d have a 10% chance to find <span class="math inline">\(\bar{x}=\mu\)</span>… and a 90% chance not to!).</p>
</blockquote>
<p>In general, the larger the sample size, the smaller the sampling error tends to be in estimating <span class="math inline">\(\mu\)</span> using <span class="math inline">\(\bar{x}\)</span>.</p>
<p>In practice, we have one sample and <span class="math inline">\(\mu\)</span> is unknown. We also have limited resources to collect data, so it may not be feasible to collect a very large sample.</p>
<p>The mean of the distribution of <span class="math inline">\(\bar{x}\)</span> is <span class="math inline">\(\mu_{\bar{X}}=\mu\)</span> and the standard deviation is <span class="math inline">\(\sigma_{\bar{X}}=\sigma/\sqrt{n}\)</span>. We refer to the standard deviation of a sampling distribution as <strong>standard error</strong>. (Note that this standard error formula is built for very large populations, so it will not work well for our basketball players. This is okay! We usually work with populations so large that we treat them as “infinite.”)</p>
<blockquote>
<p><em>Example</em>: The mean living space for a detatched single family home in the United States is 1742 ft<span class="math inline">\(^2\)</span> with a standard deviation of 568 square feet. (Does that mean seem huge to anyone else??) For samples of 25 homes, determine the mean and standard error of <span class="math inline">\(\bar{x}\)</span>.</p>
<p>Using our formulae: <span class="math display">\[\mu_{\bar{X}} = \mu = 1742\]</span> and <span class="math display">\[\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{568}{\sqrt{25}} = 113.6.\]</span></p>
</blockquote>
</div>
<div id="the-sampling-distribution-of-barx" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> The Sampling Distribution of <span class="math inline">\(\bar{X}\)</span><a href="introduction-to-inference.html#the-sampling-distribution-of-barx" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>First, we consider the setting where <span class="math inline">\(X\)</span> is Normal(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>). The plots below show (A) a random sample of 1000 from a Normal(100, 25) distribution and (B) the approximate sampling distribution of <span class="math inline">\(\bar{X}\)</span> when X is Normal(100, 25).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="introduction-to-inference.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb1-2"><a href="introduction-to-inference.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb1-3"><a href="introduction-to-inference.html#cb1-3" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1000000</span>,<span class="dv">100</span>,<span class="dv">25</span>), <span class="at">nrow=</span><span class="dv">1000</span>, <span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb1-4"><a href="introduction-to-inference.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(dat[<span class="dv">1</span>,], <span class="at">freq=</span><span class="cn">FALSE</span>, <span class="at">main=</span><span class="st">&quot;Distribution of x&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb1-5"><a href="introduction-to-inference.html#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">rowMeans</span>(dat), <span class="at">freq=</span><span class="cn">FALSE</span>, <span class="at">main=</span><span class="st">&quot;Distribution of x-bar&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;x-bar&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Notice how the x-axis changes from one plot to the next.</p>
<p>In fact, if <span class="math inline">\(X\)</span> is Normal(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>), then <span class="math inline">\(\bar{X}\)</span> is Normal(<span class="math inline">\(\mu_{\bar{X}}=\mu\)</span>, <span class="math inline">\(\sigma_{\bar{X}}=\sigma/\sqrt{n}\)</span>).</p>
<center>
<font size='4'><b>Central Limit Theorem</b></font>
</center>
<p>For relatively large sample sizes, the random variable <span class="math inline">\(\bar{X}\)</span> is approximately normally distributed <em>regardless of the distribution of</em> <span class="math inline">\(X\)</span>: <span class="math display">\[\bar{X}\text{ is Normal}(\mu_{\bar{X}}=\mu, \sigma_{\bar{X}}=\sigma/\sqrt{n}).\]</span></p>
<p>Notes</p>
<ul>
<li>This approximation improves with increasing sample size.</li>
<li>In general, “relatively large” means sample sizes <span class="math inline">\(n \ge 30\)</span>.</li>
</ul>
</div>
</div>
<div id="developing-confidence-intervals" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Developing Confidence Intervals<a href="introduction-to-inference.html#developing-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recall: A <strong>point estimate</strong> is a single-value estimate of a population parameter. We say that a statistic is an <strong>unbiased estimator</strong> if the mean of its distribution is equal to the population parameter. Otherwise, it is a <strong>biased estimator</strong>.</p>
<p><em>Comment</em> Remember how our formula for standard deviation, the “mean squared deviance” divides by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>? We do this so that <span class="math inline">\(s\)</span> is an <em>unbiased</em> estimate of <span class="math inline">\(\sigma\)</span>.</p>
<p>Ideally, we want estimates that are unbiased with small standard error. For example, a sample mean (unbiased) with a large sample size (results in smaller standard error).</p>
<p>Point estimates are useful, but they only give us so much information. The variability of an estimate is also important!</p>
<blockquote>
<p><em>Example</em> Think about estimating what tomorrow’s weather will be like. If it’s May in Sacramento, the average high temperature is 82 degrees Fahrenheit, but it’s not uncommon to have highs anywhere from 75 to 90! Since the highs are so <em>variable</em>, it’s hard to be confident using 82 to predict tomorrow’s weather.</p>
<p>On the flip side, think about July in Phoenix. The average high is 106 degrees Fahrenheit. In Phoenix, it’s uncommon to have a July day with a high below 100. Since the highs are <em>not variable</em>, you could feel pretty confident using 105 to predict tomorrow’s weather.</p>
</blockquote>
<p>Take a look at these two boxplots:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="introduction-to-inference.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb2-2"><a href="introduction-to-inference.html#cb2-2" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="fl">0.5</span>), <span class="fu">runif</span>(<span class="dv">100</span>,<span class="sc">-</span><span class="dv">5</span>,<span class="dv">5</span>))</span>
<span id="cb2-3"><a href="introduction-to-inference.html#cb2-3" aria-hidden="true" tabindex="-1"></a>grp <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>,<span class="dv">100</span>),<span class="fu">rep</span>(<span class="dv">2</span>,<span class="dv">100</span>))</span>
<span id="cb2-4"><a href="introduction-to-inference.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(dat<span class="sc">~</span>grp, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Both samples are size <span class="math inline">\(n=100\)</span> and have <span class="math inline">\(\bar{x}=0\)</span>, which would be our point estimate for <span class="math inline">\(\mu\)</span>… but Variable 1 has a standard deviation of <span class="math inline">\(\sigma=0.5\)</span> and Variable 2 has standard deviation <span class="math inline">\(\sigma=5\)</span>. As a result, we can be more confident in our estimate of the population mean for Variable 1 than for Variable 2.</p>
<p>We want to formalize this idea of confidence in our estimates. A <strong>confidence interval</strong> is an interval of numbers based on the point estimate of the parameter. Say we want to be 95% confident about a statement. In Statistics, this means that we have arrived at our statement using a method that will give us a correct statement 95% of the time.</p>
<p>Assume we are taking a sample from a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. We will assume the value of <span class="math inline">\(\sigma\)</span> is known to us. Then <span class="math inline">\(\bar{X}\)</span> is Normal(<span class="math inline">\(\mu, \sigma/\sqrt{n}\)</span>). If we standardize <span class="math inline">\(\bar{X}\)</span>, we get <span class="math display">\[Z = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}.\]</span></p>
<p>We want some interval <span class="math inline">\((a,b)\)</span>. We will start by considering <span class="math inline">\(a &lt; Z &lt; b\)</span>, so <span class="math inline">\(a &lt; Z\)</span> and <span class="math inline">\(Z &lt; b\)</span> (or <span class="math inline">\(b &gt; Z\)</span>). Then</p>
<p><span class="math display">\[
\begin{aligned}
Z &amp;&lt; b\\
\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} &amp;&lt; b\\
\bar{X}-\mu &amp;&lt; b\sigma/\sqrt{n} \\
\bar{X}-b\sigma/\sqrt{n} &amp;&lt; \mu 
\end{aligned}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\begin{aligned}
a &amp;&lt; Z  \\
a &amp;&lt; \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \\
a\sigma/\sqrt{n} &amp;&lt; \bar{X}-\mu \\
\mu &amp;&lt; \bar{X}-a\sigma/\sqrt{n}
\end{aligned}
\]</span></p>
<p>putting these together, <span class="math display">\[ \bar{X}-b\frac{\sigma}{\sqrt{n}} &lt; \mu &lt;  \bar{X}-a\frac{\sigma}{\sqrt{n}}.\]</span> If we want to be 95% confident, then we want <span class="math inline">\(P(a &lt; Z &lt; b)=0.95\)</span>: <span class="math display">\[P\left(\bar{X}-b\frac{\sigma}{\sqrt{n}} &lt; \mu &lt;  \bar{X}-a\frac{\sigma}{\sqrt{n}}\right) = 0.95.\]</span> To calculate the 95% confidence interval, we need to find <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that <span class="math inline">\(P(a &lt; Z &lt; b)=0.95\)</span>.</p>
<p>We want this interval to be as narrow (small) as possible. Why? Narrower intervals are more informative. If I say I’m 95% confidence that tomorrow’s high will be between -100 and 200 degrees Fahrenheit, that’s a useless interval. If I change it to between 70 and 100, that’s a little better. Changing it to between 85 and 90 is even better. This is what we mean by more informative.</p>
<p>It turns out that, with a symmetric distribution like the normal distribution, the way to make a confidence interval as narrow as possible is to take advantage of this symmetry. Each of the plots below show a shaded area of 0.95. The narrowest interval (along the horizontal axis) is the first interval, which is shaded on <span class="math inline">\((-1.96 &lt; z &lt; 1.96)\)</span>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="introduction-to-inference.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb3-2"><a href="introduction-to-inference.html#cb3-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>,<span class="at">length.out=</span><span class="dv">1000</span>)</span>
<span id="cb3-3"><a href="introduction-to-inference.html#cb3-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x)</span>
<span id="cb3-4"><a href="introduction-to-inference.html#cb3-4" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">qnorm</span>(<span class="fl">0.975</span>); x2 <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>)</span>
<span id="cb3-5"><a href="introduction-to-inference.html#cb3-5" aria-hidden="true" tabindex="-1"></a>x.coord <span class="ot">&lt;-</span> <span class="fu">c</span>(x[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2])</span>
<span id="cb3-6"><a href="introduction-to-inference.html#cb3-6" aria-hidden="true" tabindex="-1"></a>y.coord <span class="ot">&lt;-</span> y[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2]</span>
<span id="cb3-7"><a href="introduction-to-inference.html#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&#39;l&#39;</span>, <span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>) <span class="co">#</span></span>
<span id="cb3-8"><a href="introduction-to-inference.html#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>); <span class="fu">abline</span>(<span class="at">v=</span><span class="dv">1100</span>)</span>
<span id="cb3-9"><a href="introduction-to-inference.html#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="at">x=</span>x.coord, <span class="at">y=</span> <span class="fu">c</span>(<span class="dv">0</span>, y.coord[<span class="dv">2</span><span class="sc">:</span>(<span class="fu">length</span>(y.coord)<span class="sc">-</span><span class="dv">1</span>)], <span class="dv">0</span>), <span class="at">col=</span><span class="st">&quot;mistyrose&quot;</span>)</span>
<span id="cb3-10"><a href="introduction-to-inference.html#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="introduction-to-inference.html#cb3-11" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">3</span>; x2 <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.95</span>)</span>
<span id="cb3-12"><a href="introduction-to-inference.html#cb3-12" aria-hidden="true" tabindex="-1"></a>x.coord <span class="ot">&lt;-</span> <span class="fu">c</span>(x[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2])</span>
<span id="cb3-13"><a href="introduction-to-inference.html#cb3-13" aria-hidden="true" tabindex="-1"></a>y.coord <span class="ot">&lt;-</span> y[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2]</span>
<span id="cb3-14"><a href="introduction-to-inference.html#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&#39;l&#39;</span>, <span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>) <span class="co">#</span></span>
<span id="cb3-15"><a href="introduction-to-inference.html#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>); <span class="fu">abline</span>(<span class="at">v=</span><span class="dv">1100</span>)</span>
<span id="cb3-16"><a href="introduction-to-inference.html#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="at">x=</span>x.coord, <span class="at">y=</span> <span class="fu">c</span>(<span class="dv">0</span>, y.coord[<span class="dv">2</span><span class="sc">:</span>(<span class="fu">length</span>(y.coord)<span class="sc">-</span><span class="dv">1</span>)], <span class="dv">0</span>), <span class="at">col=</span><span class="st">&quot;mistyrose&quot;</span>)</span>
<span id="cb3-17"><a href="introduction-to-inference.html#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="introduction-to-inference.html#cb3-18" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">qnorm</span>(<span class="fl">0.95</span>); x2 <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb3-19"><a href="introduction-to-inference.html#cb3-19" aria-hidden="true" tabindex="-1"></a>x.coord <span class="ot">&lt;-</span> <span class="fu">c</span>(x[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2])</span>
<span id="cb3-20"><a href="introduction-to-inference.html#cb3-20" aria-hidden="true" tabindex="-1"></a>y.coord <span class="ot">&lt;-</span> y[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2]</span>
<span id="cb3-21"><a href="introduction-to-inference.html#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&#39;l&#39;</span>, <span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>) <span class="co">#</span></span>
<span id="cb3-22"><a href="introduction-to-inference.html#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>); <span class="fu">abline</span>(<span class="at">v=</span><span class="dv">1100</span>)</span>
<span id="cb3-23"><a href="introduction-to-inference.html#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="at">x=</span>x.coord, <span class="at">y=</span> <span class="fu">c</span>(<span class="dv">0</span>, y.coord[<span class="dv">2</span><span class="sc">:</span>(<span class="fu">length</span>(y.coord)<span class="sc">-</span><span class="dv">1</span>)], <span class="dv">0</span>), <span class="at">col=</span><span class="st">&quot;mistyrose&quot;</span>)</span>
<span id="cb3-24"><a href="introduction-to-inference.html#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="introduction-to-inference.html#cb3-25" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">qnorm</span>(<span class="fl">0.99</span>); x2 <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.96</span>)</span>
<span id="cb3-26"><a href="introduction-to-inference.html#cb3-26" aria-hidden="true" tabindex="-1"></a>x.coord <span class="ot">&lt;-</span> <span class="fu">c</span>(x[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2])</span>
<span id="cb3-27"><a href="introduction-to-inference.html#cb3-27" aria-hidden="true" tabindex="-1"></a>y.coord <span class="ot">&lt;-</span> y[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2]</span>
<span id="cb3-28"><a href="introduction-to-inference.html#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&#39;l&#39;</span>, <span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>) <span class="co">#</span></span>
<span id="cb3-29"><a href="introduction-to-inference.html#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>); <span class="fu">abline</span>(<span class="at">v=</span><span class="dv">1100</span>)</span>
<span id="cb3-30"><a href="introduction-to-inference.html#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="at">x=</span>x.coord, <span class="at">y=</span> <span class="fu">c</span>(<span class="dv">0</span>, y.coord[<span class="dv">2</span><span class="sc">:</span>(<span class="fu">length</span>(y.coord)<span class="sc">-</span><span class="dv">1</span>)], <span class="dv">0</span>), <span class="at">col=</span><span class="st">&quot;mistyrose&quot;</span>)</span></code></pre></div>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The confidence interval, then, is <span class="math display">\[\left(\bar{x} - z_*\frac{\sigma}{\sqrt{n}}, \bar{x} + z_*\frac{\sigma}{\sqrt{n}}\right)\]</span> where <span class="math inline">\(z_* = 1.96\)</span>. The midpoint of this interval is <span class="math inline">\(\bar{x}\)</span>. The value of <span class="math display">\[z_*\frac{\sigma}{\sqrt{n}}\]</span> is called the <strong>margin of error</strong>.</p>
<div id="interpreting-a-confidence-interval" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Interpreting a Confidence Interval<a href="introduction-to-inference.html#interpreting-a-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To interpret a confidence interval, we need to think back to our definition of probability as “the proportion of times is would occur if the experiment were run infinitely many times.” In the confidence interval case, if an experiment is run infinitely many times, the true value of <span class="math inline">\(\mu\)</span> will be contained in 95% of the intervals.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="introduction-to-inference.html#cb4-1" aria-hidden="true" tabindex="-1"></a>contains <span class="ot">&lt;-</span> <span class="cf">function</span>(l,u,m){</span>
<span id="cb4-2"><a href="introduction-to-inference.html#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(l <span class="sc">&lt;</span> m <span class="sc">&amp;</span> m <span class="sc">&lt;</span> u) <span class="fu">return</span>(<span class="cn">TRUE</span>)</span>
<span id="cb4-3"><a href="introduction-to-inference.html#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span> <span class="fu">return</span>(<span class="cn">FALSE</span>)</span>
<span id="cb4-4"><a href="introduction-to-inference.html#cb4-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-5"><a href="introduction-to-inference.html#cb4-5" aria-hidden="true" tabindex="-1"></a>plot_ci <span class="ot">&lt;-</span> <span class="cf">function</span>(lo, hi, m){</span>
<span id="cb4-6"><a href="introduction-to-inference.html#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mgp=</span><span class="fu">c</span>(<span class="fl">2.7</span>, <span class="fl">0.7</span>, <span class="dv">0</span>))</span>
<span id="cb4-7"><a href="introduction-to-inference.html#cb4-7" aria-hidden="true" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb4-8"><a href="introduction-to-inference.html#cb4-8" aria-hidden="true" tabindex="-1"></a>  ci.max <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="fu">rowSums</span>(<span class="fu">matrix</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">*</span>lo,hi),<span class="at">ncol=</span><span class="dv">2</span>)))</span>
<span id="cb4-9"><a href="introduction-to-inference.html#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="introduction-to-inference.html#cb4-10" aria-hidden="true" tabindex="-1"></a>  xR <span class="ot">&lt;-</span> m <span class="sc">+</span> ci.max<span class="sc">*</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-11"><a href="introduction-to-inference.html#cb4-11" aria-hidden="true" tabindex="-1"></a>  yR <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">41</span><span class="sc">*</span>k<span class="sc">/</span><span class="dv">40</span>)</span>
<span id="cb4-12"><a href="introduction-to-inference.html#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="introduction-to-inference.html#cb4-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(xR, yR, <span class="at">type=</span><span class="st">&#39;n&#39;</span>, <span class="at">xlab=</span><span class="st">&#39;&#39;</span>, <span class="at">ylab=</span><span class="st">&#39;&#39;</span>, <span class="at">axes=</span><span class="cn">FALSE</span>)</span>
<span id="cb4-14"><a href="introduction-to-inference.html#cb4-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v=</span>m, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&#39;#00000088&#39;</span>)</span>
<span id="cb4-15"><a href="introduction-to-inference.html#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at=</span>m, <span class="fu">paste</span>(<span class="st">&quot;mu = &quot;</span>,<span class="fu">round</span>(m,<span class="dv">4</span>)), <span class="at">cex.axis=</span><span class="fl">1.15</span>)</span>
<span id="cb4-16"><a href="introduction-to-inference.html#cb4-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">#axis(2)</span></span>
<span id="cb4-17"><a href="introduction-to-inference.html#cb4-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k){</span>
<span id="cb4-18"><a href="introduction-to-inference.html#cb4-18" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">c</span>(hi[i],lo[i]))</span>
<span id="cb4-19"><a href="introduction-to-inference.html#cb4-19" aria-hidden="true" tabindex="-1"></a>      ci <span class="ot">&lt;-</span> <span class="fu">c</span>(lo[i],hi[i])</span>
<span id="cb4-20"><a href="introduction-to-inference.html#cb4-20" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(<span class="fu">contains</span>(lo[i],hi[i],m)<span class="sc">==</span><span class="cn">FALSE</span>){</span>
<span id="cb4-21"><a href="introduction-to-inference.html#cb4-21" aria-hidden="true" tabindex="-1"></a>          col <span class="ot">&lt;-</span> <span class="st">&quot;#F05133&quot;</span></span>
<span id="cb4-22"><a href="introduction-to-inference.html#cb4-22" aria-hidden="true" tabindex="-1"></a>          <span class="fu">points</span>(x, i, <span class="at">cex=</span><span class="fl">1.4</span>, <span class="at">col=</span>col)</span>
<span id="cb4-23"><a href="introduction-to-inference.html#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co">#         points(x, i, pch=20, cex=1.2, col=col)</span></span>
<span id="cb4-24"><a href="introduction-to-inference.html#cb4-24" aria-hidden="true" tabindex="-1"></a>          <span class="fu">lines</span>(ci, <span class="fu">rep</span>(i, <span class="dv">2</span>), <span class="at">col=</span>col, <span class="at">lwd=</span><span class="dv">5</span>)</span>
<span id="cb4-25"><a href="introduction-to-inference.html#cb4-25" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb4-26"><a href="introduction-to-inference.html#cb4-26" aria-hidden="true" tabindex="-1"></a>      col <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb4-27"><a href="introduction-to-inference.html#cb4-27" aria-hidden="true" tabindex="-1"></a>    <span class="fu">points</span>(x, i, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">cex=</span><span class="dv">1</span>, <span class="at">col=</span>col)</span>
<span id="cb4-28"><a href="introduction-to-inference.html#cb4-28" aria-hidden="true" tabindex="-1"></a>      <span class="fu">lines</span>(ci, <span class="fu">rep</span>(i, <span class="dv">2</span>), <span class="at">col=</span>col)</span>
<span id="cb4-29"><a href="introduction-to-inference.html#cb4-29" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-30"><a href="introduction-to-inference.html#cb4-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-31"><a href="introduction-to-inference.html#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="introduction-to-inference.html#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb4-33"><a href="introduction-to-inference.html#cb4-33" aria-hidden="true" tabindex="-1"></a>population <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000000</span>,<span class="dv">80</span>,<span class="dv">25</span>)</span>
<span id="cb4-34"><a href="introduction-to-inference.html#cb4-34" aria-hidden="true" tabindex="-1"></a>samp_mean <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="dv">100</span>)</span>
<span id="cb4-35"><a href="introduction-to-inference.html#cb4-35" aria-hidden="true" tabindex="-1"></a>samp_sd <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="dv">100</span>)</span>
<span id="cb4-36"><a href="introduction-to-inference.html#cb4-36" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">60</span></span>
<span id="cb4-37"><a href="introduction-to-inference.html#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb4-38"><a href="introduction-to-inference.html#cb4-38" aria-hidden="true" tabindex="-1"></a>  samp <span class="ot">&lt;-</span> <span class="fu">sample</span>(population, n) <span class="co"># obtain a sample of size n = 60 from the population</span></span>
<span id="cb4-39"><a href="introduction-to-inference.html#cb4-39" aria-hidden="true" tabindex="-1"></a>  samp_mean[i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(samp)    <span class="co"># save sample mean in ith element of samp_mean</span></span>
<span id="cb4-40"><a href="introduction-to-inference.html#cb4-40" aria-hidden="true" tabindex="-1"></a>  samp_sd[i] <span class="ot">&lt;-</span> <span class="fu">sd</span>(samp)        <span class="co"># save sample sd in ith element of samp_sd</span></span>
<span id="cb4-41"><a href="introduction-to-inference.html#cb4-41" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-42"><a href="introduction-to-inference.html#cb4-42" aria-hidden="true" tabindex="-1"></a>cv <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">qnorm</span>(<span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb4-43"><a href="introduction-to-inference.html#cb4-43" aria-hidden="true" tabindex="-1"></a>lower_vector <span class="ot">&lt;-</span> samp_mean <span class="sc">-</span> cv <span class="sc">*</span> samp_sd <span class="sc">/</span> <span class="fu">sqrt</span>(n) </span>
<span id="cb4-44"><a href="introduction-to-inference.html#cb4-44" aria-hidden="true" tabindex="-1"></a>upper_vector <span class="ot">&lt;-</span> samp_mean <span class="sc">+</span> cv <span class="sc">*</span> samp_sd <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb4-45"><a href="introduction-to-inference.html#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_ci</span>(lower_vector, upper_vector, <span class="dv">80</span>)</span></code></pre></div>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>The graphic above shows 95% confidence intervals for 100 samples of size <span class="math inline">\(n=60\)</span> drawn from a population with mean <span class="math inline">\(\mu=80\)</span> and standard deviation <span class="math inline">\(\sigma=25\)</span>. Each sample’s confidence interval is represented by a horizontal line. The dot in the middle of each is the sample mean. When a confidence interval does <em>not</em> capture the population mean <span class="math inline">\(\mu\)</span>, the line is printed in red. Based on this concept of repeated sampling, we would expect about 95% of these intervals to capture <span class="math inline">\(\mu\)</span>. In fact, 96 of the 100 intervals capture <span class="math inline">\(\mu\)</span>.</p>
<p>Finally, when you interpret a confidence interval, it is important to do so in the context of the problem.</p>
<blockquote>
<p><em>Example</em> The preferred keyboard height for typists is approximately normally distributed with <span class="math inline">\(\sigma=2.0\)</span>. A sample of size <span class="math inline">\(n=31\)</span>, resulted in a mean prefered keyboard height of <span class="math inline">\(80 cm\)</span>. Find and interpret a 95% confidence interval for keyboard height.</p>
<p>The interval is <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}} = 80.0 \pm 1.96\times\frac{2.0}{\sqrt{31}} = 80.0 \pm 0.70 = (79.3, 80.7).\]</span> Interpretation:We can be 95% confident that the mean preferred keyboard height for typists is between 79.3cm and 80.7cm.</p>
</blockquote>
<p>Notice that I kept the interpretation simple! That’s okay - just be sure you are <em>also</em> able to explain what it means to be 95% confident (using the concept of repeated sampling).</p>
<p>Common mistakes:</p>
<ul>
<li>It is NOT accurate to say that “the probability that <span class="math inline">\(\mu\)</span> is in the confidence interval is 0.95.” The parameter <span class="math inline">\(\mu\)</span> is some fixed quantity and it’s either in the interval or it isn’t.</li>
<li>We are NOT “95% confident that <span class="math inline">\(\bar{x}\)</span> is in the interval.” The value <span class="math inline">\(\bar{x}\)</span> is some known quantity and it’s always in the interval.</li>
</ul>
</div>
<div id="exercises-1" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Exercises<a href="introduction-to-inference.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Suppose I took a random sample of 50 Sac State students and asked about their SAT scores and found a mean score of 1112. Prior experience with SAT scores in the CSU system suggests that SAT scores are well-approximated by a normal distribution with standard deviation known to be 50.
<ol style="list-style-type: lower-alpha">
<li>Find a 95% confidence interval for Sac State SAT scores.</li>
<li>Interpret your interval in the context of the problem.</li>
<li>What is the width of your interval? If you want a narrower interval, what could you do?</li>
</ol></li>
</ol>
</div>
</div>
<div id="other-levels-of-confidence" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Other Levels of Confidence<a href="introduction-to-inference.html#other-levels-of-confidence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>While the 95% confidence interval is common in research, there’s nothing inherently special about it. You could calculate a 90%, a 99%, or - if you’re feeling spicy - something like a 43.8% confidence interval. These numbers are called the <strong>confidence level</strong> and they represent the proportion of times that the parameter will fall in the interval (if we took many samples).</p>
<p>The 100(1-<span class="math inline">\(\alpha\)</span>)% confidence interval for <span class="math inline">\(\mu\)</span> is given by <span class="math display">\[\bar{x}\pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\]</span> where <span class="math inline">\(z_{\alpha/2}\)</span> is the z-score associated with the <span class="math inline">\([1-(\alpha/2)]\)</span>th percentile of the standard normal distribution. The value <span class="math inline">\(z_{\alpha/2}\)</span> is called the <strong>critical value</strong> (“c.v.” on the plot, below).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="introduction-to-inference.html#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>,<span class="at">length.out=</span><span class="dv">1000</span>)</span>
<span id="cb5-2"><a href="introduction-to-inference.html#cb5-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x)</span>
<span id="cb5-3"><a href="introduction-to-inference.html#cb5-3" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">3</span>; x2 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">qnorm</span>(<span class="fl">0.85</span>); x3 <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.85</span>); x4 <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb5-4"><a href="introduction-to-inference.html#cb5-4" aria-hidden="true" tabindex="-1"></a>x.coord <span class="ot">&lt;-</span> <span class="fu">c</span>(x[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2])</span>
<span id="cb5-5"><a href="introduction-to-inference.html#cb5-5" aria-hidden="true" tabindex="-1"></a>y.coord <span class="ot">&lt;-</span> y[x <span class="sc">&gt;</span> x1 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x2]</span>
<span id="cb5-6"><a href="introduction-to-inference.html#cb5-6" aria-hidden="true" tabindex="-1"></a>x.coord2 <span class="ot">&lt;-</span> <span class="fu">c</span>(x[x <span class="sc">&gt;</span> x3 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x4])</span>
<span id="cb5-7"><a href="introduction-to-inference.html#cb5-7" aria-hidden="true" tabindex="-1"></a>y.coord2 <span class="ot">&lt;-</span> y[x <span class="sc">&gt;</span> x3 <span class="sc">&amp;</span> x <span class="sc">&lt;</span> x4]</span>
<span id="cb5-8"><a href="introduction-to-inference.html#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&#39;l&#39;</span>, <span class="at">xaxt=</span><span class="st">&#39;n&#39;</span>, <span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.02</span>,<span class="fu">max</span>(y)<span class="sc">+</span><span class="fl">0.01</span>)) <span class="co">#</span></span>
<span id="cb5-9"><a href="introduction-to-inference.html#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>); <span class="fu">abline</span>(<span class="at">v=</span><span class="dv">1100</span>)</span>
<span id="cb5-10"><a href="introduction-to-inference.html#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="at">x=</span>x.coord, <span class="at">y=</span> <span class="fu">c</span>(<span class="dv">0</span>, y.coord[<span class="dv">2</span><span class="sc">:</span>(<span class="fu">length</span>(y.coord)<span class="sc">-</span><span class="dv">1</span>)], <span class="dv">0</span>), <span class="at">col=</span><span class="st">&quot;mistyrose&quot;</span>)</span>
<span id="cb5-11"><a href="introduction-to-inference.html#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="at">x=</span>x.coord2, <span class="at">y=</span> <span class="fu">c</span>(<span class="dv">0</span>, y.coord2[<span class="dv">2</span><span class="sc">:</span>(<span class="fu">length</span>(y.coord)<span class="sc">-</span><span class="dv">1</span>)], <span class="dv">0</span>), <span class="at">col=</span><span class="st">&quot;mistyrose&quot;</span>)</span>
<span id="cb5-12"><a href="introduction-to-inference.html#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="sc">-</span><span class="fl">1.6</span>,<span class="fl">0.03</span>,<span class="st">&quot;Area = a/2&quot;</span>); <span class="fu">text</span>(<span class="fl">1.6</span>,<span class="fl">0.03</span>,<span class="st">&quot;Area = a/2&quot;</span>); <span class="fu">text</span>(<span class="dv">0</span>,<span class="fl">0.1</span>,<span class="st">&quot;Area = 1-a&quot;</span>)</span>
<span id="cb5-13"><a href="introduction-to-inference.html#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(x2, <span class="fl">0.</span><span class="sc">-</span><span class="fl">0.015</span>, <span class="st">&quot;-c.v.&quot;</span>); <span class="fu">text</span>(x3, <span class="sc">-</span><span class="fl">0.015</span>, <span class="st">&quot;+c.v.&quot;</span>)</span></code></pre></div>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>We can find critical values in <code>R</code> using the same command we used to find percentiles: <code>qnorm(p)</code>. We want a 100(1-<span class="math inline">\(\alpha\)</span>)% confidence interval, so we need to quickly solve for <span class="math inline">\(\alpha\)</span> and divide by 2. For example, for a 98% interval, <span class="math display">\[100(1-\alpha) = 98 \implies \alpha=0.02\]</span> Then <span class="math inline">\(\alpha/2 = 0.01\)</span> and</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="introduction-to-inference.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.01</span>)</span></code></pre></div>
<pre><code>## [1] -2.326348</code></pre>
<p>So the critical value is <span class="math inline">\(z_{\alpha/2}=2.326\)</span>. Notice that I dropped the negative sign here. That’s because our formula uses <span class="math inline">\(\pm z_{\alpha/2}\)</span>, so the sign doesn’t matter. I’ll always ignore that negative for critical values. As long as you write your interval as <span class="math inline">\((\text{smaller number}, \text{bigger number})\)</span>, it’s all good.</p>
<center>
<font size='4'><b>Common Critical Values</b></font>
</center>
<table>
<thead>
<tr class="header">
<th align="center">Confidence Level</th>
<th align="center"><span class="math inline">\(\alpha\)</span></th>
<th align="center">Critical Value, <span class="math inline">\(z_{\alpha/2}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">90%</td>
<td align="center">0.10</td>
<td align="center">1.645</td>
</tr>
<tr class="even">
<td align="center">95%</td>
<td align="center">0.05</td>
<td align="center">1.96</td>
</tr>
<tr class="odd">
<td align="center">98%</td>
<td align="center">0.02</td>
<td align="center">2.326</td>
</tr>
<tr class="even">
<td align="center">99%</td>
<td align="center">0.01</td>
<td align="center">2.575</td>
</tr>
</tbody>
</table>
<div id="breaking-down-a-confidence-interval" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Breaking Down a Confidence Interval<a href="introduction-to-inference.html#breaking-down-a-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider <span class="math display">\[\left(\bar{x}- z_{\alpha/2}\frac{\sigma}{\sqrt{n}}, \quad \bar{x} + z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\right)\]</span> The key values are</p>
<ul>
<li><span class="math inline">\(\bar{x}\)</span>, the sample mean</li>
<li><span class="math inline">\(\sigma\)</span>, the population standard deviation</li>
<li><span class="math inline">\(n\)</span>, the sample size</li>
<li><span class="math inline">\(z_{\alpha/2}\)</span>, the critical value <span class="math display">\[P(Z &gt; z_{\alpha/2}) = \frac{\alpha}{2}\]</span></li>
</ul>
<p>The value of interest is <span class="math inline">\(\mu\)</span>, the (unknown) population mean; the confidence interval gives us a reasonable range of values for <span class="math inline">\(\mu\)</span>.</p>
<p>In addition, the formula includes</p>
<ul>
<li>The standard error, <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span></li>
<li>The margin of error, <span class="math inline">\(z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\)</span></li>
</ul>
</div>
<div id="confidence-level-precision-and-sample-size" class="section level3 hasAnchor" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Confidence Level, Precision, and Sample Size<a href="introduction-to-inference.html#confidence-level-precision-and-sample-size" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we can be 99% confident (or even higher), why do we tend to “settle” for 95%?? Take a look at the common critical values (above) and the confidence interval formula <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}.\]</span> What will higher levels of confidence do to this interval? Think back to the intuitive interval width explanation with the weather. Mathematically, the same thing will happen: the interval will get wider! And remember, a narrow interval is a more informative interval. There is a trade off here between interval width and confidence. In general, the scientific community has settled on 95% as a compromise between the two, but different fields may use different levels of confidence.</p>
<p>There is one other thing we can control in the confidence interval: the sample size <span class="math inline">\(n\)</span>. One strategy is to specify the confidence level and the maximum acceptable interval width and use these to determine sample size. We know that <span class="math display">\[\text{interval width} \ge 2z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\]</span> (Note: I use <span class="math inline">\(\ge\)</span> because <span class="math inline">\(2z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\)</span> is the <em>maximum</em> interval width - we would still be happy if this value turned out to be smaller!) Letting interval width equal <span class="math inline">\(w\)</span>, we can solve for <span class="math inline">\(n\)</span>: <span class="math display">\[ n \ge \left(2z_{\alpha/2}\frac{\sigma}{w}\right)^2\]</span> Alternately, we may specify a maximum margin of error <span class="math inline">\(m\)</span> instead: <span class="math display">\[ n \ge \left(z_{\alpha/2}\frac{\sigma}{m}\right)^2\]</span> Once we’ve done this calculation, we need a whole number for <span class="math inline">\(n\)</span>. Since <span class="math inline">\(n \ge\)</span> something, we will <em>always round up</em>.</p>
<blockquote>
<p><em>Example</em> Suppose we want a 95% confidence interval for the mean of a normally distributed population with standard deviation <span class="math inline">\(\sigma=10\)</span>. It is important for our margin of error to be no more than 2. What sample size do we need?</p>
<p>Using the formula for sample size with a desired margin of error, I can plug in <span class="math inline">\(z_{0.05/2}=1.96\)</span>, <span class="math inline">\(m=2\)</span> and <span class="math inline">\(\sigma=10\)</span>: <span class="math display">\[n = \left(1.96\times\frac{10}{2}\right)^2 = 96.04\]</span>. So (rounding up!) I need a sample size of <em>at least 97</em>.</p>
</blockquote>
<p>A few comments:</p>
<ul>
<li>As desired width/margin of error decreases, <span class="math inline">\(n\)</span> will increase.</li>
<li>As <span class="math inline">\(\sigma\)</span> increases, <span class="math inline">\(n\)</span> will also increase. (More population variability will necessitate a larger sample size.)</li>
<li>As confidence level increases, <span class="math inline">\(n\)</span> will also increase.</li>
</ul>
</div>
<div id="exercises-2" class="section level3 hasAnchor" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Exercises<a href="introduction-to-inference.html#exercises-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>In the previous section, you worked with a random sample of 50 Sac State students with mean SAT score 1112. Prior experience with SAT scores in the CSU system suggests that SAT scores are well-approximated by a normal distribution with standard deviation known to be 50. Calculate a
<ol style="list-style-type: lower-alpha">
<li>98% confidence interval.</li>
<li>90% confidence interval.</li>
<li>Interpret each interval in the context of the problem. Comment on how the intervals change as you change the confidence level.</li>
<li>Find the sample size required for a 98% confidence interval with maximum margin of error 10.</li>
</ol></li>
</ol>
</div>
</div>
<div id="confidence-intervals-sigma-unknown" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Confidence Intervals, <span class="math inline">\(\sigma\)</span> Unknown<a href="introduction-to-inference.html#confidence-intervals-sigma-unknown" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In practice, the value of <span class="math inline">\(\sigma\)</span> is almost never known… but we know that we can estimate <span class="math inline">\(\sigma\)</span> using <span class="math inline">\(s\)</span>. Can we plug in <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span>? Sometimes!</p>
<p>Remember the Central Limit Theorem (Section 5.1)? For samples of size <span class="math inline">\(n \ge 30\)</span>, <span class="math inline">\(\bar{X}\)</span> will be approximately normal even if <span class="math inline">\(X\)</span> isn’t. In this case, we can plug in <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span>: <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{s}{\sqrt{n}}.\]</span></p>
<p>That setting is pretty straightforward! Now we need to consider the setting where <span class="math inline">\(n &lt; 30\)</span>, which will require a bit of additional work.</p>
<div id="the-t-distribution" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> The T-Distribution<a href="introduction-to-inference.html#the-t-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Enter: the t-distribution. If <span class="math display">\[Z = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\]</span> has a standard normal distribution (for <span class="math inline">\(X\)</span> normal or <span class="math inline">\(n\ge30\)</span>), the slightly modified <span class="math display">\[T = \frac{\bar{X}-\mu}{s/\sqrt{n}}\]</span> has what we call the <strong>t-distribution</strong> with <span class="math inline">\(n-1\)</span> <strong>degrees of freedom</strong> (even when <span class="math inline">\(n &lt; 30\)</span>!). The only thing we need to know about degrees of freedom is that <span class="math inline">\(df=n-1\)</span> is the t-distribution’s only parameter.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="introduction-to-inference.html#cb8-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">4</span>,<span class="dv">4</span>,<span class="at">length.out=</span><span class="dv">1000</span>)</span>
<span id="cb8-2"><a href="introduction-to-inference.html#cb8-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x)</span>
<span id="cb8-3"><a href="introduction-to-inference.html#cb8-3" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">dt</span>(x, <span class="dv">30</span>)</span>
<span id="cb8-4"><a href="introduction-to-inference.html#cb8-4" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">dt</span>(x, <span class="dv">10</span>)</span>
<span id="cb8-5"><a href="introduction-to-inference.html#cb8-5" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> <span class="fu">dt</span>(x, <span class="dv">5</span>)</span>
<span id="cb8-6"><a href="introduction-to-inference.html#cb8-6" aria-hidden="true" tabindex="-1"></a>t4 <span class="ot">&lt;-</span> <span class="fu">dt</span>(x, <span class="dv">2</span>)</span>
<span id="cb8-7"><a href="introduction-to-inference.html#cb8-7" aria-hidden="true" tabindex="-1"></a>t5 <span class="ot">&lt;-</span> <span class="fu">dt</span>(x, <span class="dv">1</span>)</span>
<span id="cb8-8"><a href="introduction-to-inference.html#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&#39;l&#39;</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>) </span>
<span id="cb8-9"><a href="introduction-to-inference.html#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x,t1,<span class="at">type=</span><span class="st">&#39;l&#39;</span>,<span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&#39;red&#39;</span>) </span>
<span id="cb8-10"><a href="introduction-to-inference.html#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x,t2,<span class="at">type=</span><span class="st">&#39;l&#39;</span>,<span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&#39;blue&#39;</span>) </span>
<span id="cb8-11"><a href="introduction-to-inference.html#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x,t3,<span class="at">type=</span><span class="st">&#39;l&#39;</span>,<span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb8-12"><a href="introduction-to-inference.html#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x,t4,<span class="at">type=</span><span class="st">&#39;l&#39;</span>,<span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&#39;purple&#39;</span>)</span>
<span id="cb8-13"><a href="introduction-to-inference.html#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x,t5,<span class="at">type=</span><span class="st">&#39;l&#39;</span>,<span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&#39;darkorange&#39;</span>)</span>
<span id="cb8-14"><a href="introduction-to-inference.html#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="fl">1.4</span>,<span class="fl">0.4</span>,<span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Standard Normal&quot;</span>,<span class="st">&quot;T, df=30&quot;</span>,<span class="st">&quot;T, df=10&quot;</span>,<span class="st">&quot;T, df=5&quot;</span>,<span class="st">&quot;T, df=2&quot;</span>,<span class="st">&quot;T, df=1&quot;</span>),</span>
<span id="cb8-15"><a href="introduction-to-inference.html#cb8-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span><span class="fu">c</span>(<span class="st">&#39;black&#39;</span>,<span class="st">&#39;red&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;darkgreen&#39;</span>,<span class="st">&#39;purple&#39;</span>,<span class="st">&#39;darkorange&#39;</span>), <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">box.lty=</span><span class="dv">0</span>)</span></code></pre></div>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The t-distribution is symmetric and always centered at 0. When <span class="math inline">\(n\ge30\)</span>, the t-distribution is approximately equivalent to the standard normal distribution. For smaller sample sizes, the t-distribution has more area in the tails (and therefore less area in the center of the distribution).</p>
<p>For a sample of size <span class="math inline">\(n &lt; 30\)</span>, we plug in <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span> and use a t critical value (instead of a z critical value): <span class="math display">\[\bar{x} \pm t_{df, \, \alpha/2}\frac{s}{\sqrt{n}}.\]</span> The t critical value is found through <span class="math display">\[P(T_{df} &gt; t_{df, \, \alpha/2}) = \alpha/2\]</span> where <span class="math inline">\(T_{df}\)</span> is the t-distribution with <span class="math inline">\(df=n-1\)</span> degrees of freedom.</p>
<p>To find a t critical value, we will again use <code>R</code>, now with the command <code>qt(p, df)</code>. (Notice that this is similar to the command for the standard normal distribution, but instead of “norm” for normal it has “t” for the t-distribution.) For example, for a 98% interval with a sample size of 15, <span class="math display">\[100(1-\alpha) = 98 \implies \alpha=0.02\]</span> Then <span class="math inline">\(\alpha/2 = 0.01\)</span> and <span class="math inline">\(df=15-1=14\)</span>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="introduction-to-inference.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.01</span>, <span class="at">df=</span><span class="dv">14</span>)</span></code></pre></div>
<pre><code>## [1] -2.624494</code></pre>
<p>which gives the t critical value <span class="math inline">\(t_{14,\alpha/2} = 2.625\)</span>. Notice again that I am able to ignore the sign because our formula uses <span class="math inline">\(\pm t_{df,\alpha/2}\)</span>.</p>
<p>As before, if you prefer you may use the applet, <a href="http://www.rossmanchance.com/applets/2021/tcalc/tCalc.htm" target="blank">Rossman and Chance t Probability Calculator</a>, instead of <code>R</code>. For this applet, enter the degrees of freedom <span class="math inline">\(n-1\)</span> next to “df.” Then check the top box under “t-value probability” and make sure the inequality is clicked to “&gt;” . Enter the value of <span class="math inline">\(\alpha/2\)</span> for the probability. Click anywhere else on the page and the applet will automatically fill in the box under “t-value.” This is your t critical value.</p>
</div>
</div>
<div id="confidence-intervals-for-a-proportion" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Confidence Intervals for a Proportion<a href="introduction-to-inference.html#confidence-intervals-for-a-proportion" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Inference for a proportion is really similar to inference for a mean! It turns out we can apply the Central Limit Theorem to the sampling distribution for a proportion. But wait - isn’t our Central Limit Theorem only for means?</p>
<p>Think back to the binomial distribution (Section 4.3). A binomial experiment is made up of a series of Bernoulli trials, which result in 0s and 1s. If we add up these values, we get the number of successes <span class="math inline">\(x\)</span>. If we take the mean of these successes, we get the <em>proportion</em> of successes. In short, <span class="math inline">\(\bar{x} = \hat{p}\)</span> and we can work with the sampling distribution for a sample mean!</p>
<p>The mean of a Bernoulli random variable is <span class="math inline">\(\mu = p\)</span> and the standard deviation is <span class="math inline">\(\sigma = \sqrt{p(1-p)}\)</span>. So if we apply the Central Limit Theorem, <span class="math inline">\(\hat{p}\)</span> is approximately normally distributed with mean <span class="math display">\[\mu_{\hat{p}} = p\]</span> and standard error <span class="math display">\[\sigma_{\hat{p}} = \frac{\sqrt{p(1-p)}}{\sqrt{n}} = \sqrt{\frac{p(1-p)}{n}}\]</span></p>
<p>Each of the confidence intervals for a mean uses the same logic: <span class="math display">\[\text{estimate }\pm\text{ critical value }\times\text{ standard error }\]</span> Confidence intervals for a proportion will do the same. We do not know the true value of <span class="math inline">\(p\)</span> for the standard error, so we will plug in <span class="math inline">\(\hat{p}\)</span>.</p>
<center>
<font size='4'><b>A <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for <span class="math inline">\(p\)</span>.</b></font>
</center>
<p><span class="math display">\[\hat{p}\pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\]</span></p>
<p>To use this formula, we need to check that <span class="math inline">\(n\hat{p} &gt; 10\)</span> and <span class="math inline">\(n(1-\hat{p})&gt;10\)</span>. (Note that <span class="math inline">\(n\hat{p}\)</span> is the number of successes and <span class="math inline">\(n(1-\hat{p})\)</span> is the number of failures, so this is another way to check this condition!)</p>
<p>Why? This relies on a normal approximation that does not work well if either of those quantities is less than or equal to 10. (This a topic which we have skipped, but the theory behind it is similar to the theory presented here for why we can use the Central Limit Theorem with proportions.)</p>
<blockquote>
<p><strong>Example:</strong> Suppose we take a random sample of 27 US households and find that 15 of them have dogs. Find a 95% confidence interval for the proportion of US households with dogs.</p>
<p><strong>Solution:</strong> From the problem statement, <span class="math inline">\(\alpha = 0.05\)</span>. Also, <span class="math inline">\(\hat{p} = 15/27 = 0.56\)</span>. The number of successes (households with dogs) in the sample is 15 and the number of failures is 12, both greater than 10, so our assumptions are satisfied.</p>
<p>The critical value is <span class="math inline">\(z_{\alpha/2}\)</span>. Using the normal distribution applet with <span class="math inline">\(\alpha = 0.05\)</span>, this yields a value of 1.96. Plugging everything in, <span class="math display">\[\hat{p}\pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} = 0.56 \pm 1.96\sqrt{\frac{0.56\times0.44}{27}} = 0.37 \pm 0.19\]</span> or a 95% confidence interval of (0.37, 0.75).</p>
<p>Based on our sample, we can be 95% confident that the proportion of US households with dogs is between 0.37 and 0.75.</p>
</blockquote>
</div>
<div id="summary-of-confidence-interval-settings" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Summary of Confidence Interval Settings<a href="introduction-to-inference.html#summary-of-confidence-interval-settings" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<center>
<font size='4'><b>Setting: <span class="math inline">\(\mu\)</span> is target parameter, <span class="math inline">\(X\)</span> is normal, <span class="math inline">\(\sigma\)</span> known</b></font>
</center>
<ul>
<li>Critical value: <span class="math inline">\(z_{\alpha/2}\)</span></li>
<li>Confidence interval: <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\]</span></li>
</ul>
<center>
<font size='4'><b>Setting: <span class="math inline">\(\mu\)</span> is target parameter, <span class="math inline">\(n \ge 30\)</span>, <span class="math inline">\(\sigma\)</span> unknown</b></font>
</center>
<ul>
<li>Critical value: <span class="math inline">\(z_{\alpha/2}\)</span></li>
<li>Confidence interval: <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{s}{\sqrt{n}}\]</span></li>
</ul>
<center>
<font size='4'><b>Setting: <span class="math inline">\(\mu\)</span> is target parameter, <span class="math inline">\(n &lt; 30\)</span>, <span class="math inline">\(\sigma\)</span> unknown</b></font>
</center>
<ul>
<li>Critical value: <span class="math inline">\(t_{df, \alpha/2}\)</span></li>
<li>Confidence interval: <span class="math display">\[\bar{x} \pm t_{df, \alpha/2}\frac{s}{\sqrt{n}}\]</span></li>
</ul>
<center>
<font size='4'><b>Setting: <span class="math inline">\(\p\)</span> is target parameter, <span class="math inline">\(n\hat{p} &gt; 10\)</span> and <span class="math inline">\(n(1-\hat{p})&gt;10\)</span></b></font>
</center>
<ul>
<li>Critical value: <span class="math inline">\(z_{\alpha/2}\)</span></li>
<li>Confidence interval: <span class="math display">\[\hat{p}\pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\]</span></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introduction-to-hypothesis-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IntroStats.pdf", "IntroStats.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
