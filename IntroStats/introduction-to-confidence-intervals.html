<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Introduction to Confidence Intervals | Introduction to Statistics</title>
  <meta name="description" content="Chapter 5 Introduction to Confidence Intervals | Introduction to Statistics." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Introduction to Confidence Intervals | Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Chapter 5 Introduction to Confidence Intervals | Introduction to Statistics." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Introduction to Confidence Intervals | Introduction to Statistics" />
  
  <meta name="twitter:description" content="Chapter 5 Introduction to Confidence Intervals | Introduction to Statistics." />
  

<meta name="author" content="Dr. Lauren Cappiello" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="random-variables.html"/>
<link rel="next" href="introduction-to-hypothesis-testing.html"/>
<script src="libs/header-attrs-2.20.1/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistics</a></li>

<li class="divider"></li>
<li><a href="index.html#welcome-to-statistics" id="toc-welcome-to-statistics">Welcome to Statistics!</a>
<ul>
<li><a href="index.html#course-learning-outcomes" id="toc-course-learning-outcomes">Course Learning Outcomes</a></li>
<li><a href="index.html#for-the-instructor" id="toc-for-the-instructor">For the Instructor</a></li>
<li><a href="index.html#for-the-student" id="toc-for-the-student">For the Student</a>
<ul>
<li><a href="index.html#r-programming" id="toc-r-programming">R Programming</a></li>
</ul></li>
</ul></li>
<li><a href="introduction-to-data.html#introduction-to-data" id="toc-introduction-to-data"><span class="toc-section-number">1</span> Introduction to Data</a>
<ul>
<li><a href="introduction-to-data.html#chapter-overview" id="toc-chapter-overview"><span class="toc-section-number">1.1</span> Chapter Overview</a></li>
<li><a href="introduction-to-data.html#statistics-terminology" id="toc-statistics-terminology"><span class="toc-section-number">1.2</span> Statistics Terminology</a>
<ul>
<li><a href="introduction-to-data.html#r-entering-data" id="toc-r-entering-data">R: Entering Data</a></li>
<li><a href="introduction-to-data.html#section-exercises" id="toc-section-exercises">Section Exercises</a></li>
</ul></li>
<li><a href="introduction-to-data.html#sampling-and-design" id="toc-sampling-and-design"><span class="toc-section-number">1.3</span> Sampling and Design</a>
<ul>
<li><a href="introduction-to-data.html#statistical-sampling" id="toc-statistical-sampling"><span class="toc-section-number">1.3.1</span> Statistical Sampling</a></li>
<li><a href="introduction-to-data.html#experimental-design" id="toc-experimental-design"><span class="toc-section-number">1.3.2</span> Experimental Design</a></li>
<li><a href="introduction-to-data.html#r-random-number-generation" id="toc-r-random-number-generation">R: Random Number Generation</a></li>
<li><a href="introduction-to-data.html#section-exercises-1" id="toc-section-exercises-1">Section Exercises</a></li>
</ul></li>
<li><a href="introduction-to-data.html#frequency-distributions" id="toc-frequency-distributions"><span class="toc-section-number">1.4</span> Frequency Distributions</a>
<ul>
<li><a href="introduction-to-data.html#qualitative-variables" id="toc-qualitative-variables"><span class="toc-section-number">1.4.1</span> Qualitative Variables</a></li>
<li><a href="introduction-to-data.html#quantitative-variables" id="toc-quantitative-variables"><span class="toc-section-number">1.4.2</span> Quantitative Variables</a></li>
<li><a href="introduction-to-data.html#r-histograms" id="toc-r-histograms">R: Histograms</a></li>
</ul></li>
</ul></li>
<li><a href="descriptive-measures.html#descriptive-measures" id="toc-descriptive-measures"><span class="toc-section-number">2</span> Descriptive Measures</a>
<ul>
<li><a href="descriptive-measures.html#chapter-overview-1" id="toc-chapter-overview-1"><span class="toc-section-number">2.1</span> Chapter Overview</a></li>
<li><a href="descriptive-measures.html#measures-of-central-tendency" id="toc-measures-of-central-tendency"><span class="toc-section-number">2.2</span> Measures of Central Tendency</a>
<ul>
<li><a href="descriptive-measures.html#r-finding-measures-of-center" id="toc-r-finding-measures-of-center">R: Finding Measures of Center</a></li>
</ul></li>
<li><a href="descriptive-measures.html#measures-of-variability" id="toc-measures-of-variability"><span class="toc-section-number">2.3</span> Measures of Variability</a>
<ul>
<li><a href="descriptive-measures.html#r-finding-measures-of-variability" id="toc-r-finding-measures-of-variability">R: Finding Measures of Variability</a></li>
</ul></li>
<li><a href="descriptive-measures.html#measures-of-position" id="toc-measures-of-position"><span class="toc-section-number">2.4</span> Measures of Position</a>
<ul>
<li><a href="descriptive-measures.html#box-plots" id="toc-box-plots"><span class="toc-section-number">2.4.1</span> Box Plots</a></li>
<li><a href="descriptive-measures.html#r-measures-of-position" id="toc-r-measures-of-position">R: Measures of Position</a></li>
<li><a href="descriptive-measures.html#r-box-plots" id="toc-r-box-plots">R: Box Plots</a></li>
</ul></li>
<li><a href="descriptive-measures.html#descriptive-measures-for-populations" id="toc-descriptive-measures-for-populations"><span class="toc-section-number">2.5</span> Descriptive Measures for Populations</a></li>
</ul></li>
<li><a href="probability-concepts.html#probability-concepts" id="toc-probability-concepts"><span class="toc-section-number">3</span> Probability Concepts</a>
<ul>
<li><a href="probability-concepts.html#chapter-overview-2" id="toc-chapter-overview-2"><span class="toc-section-number">3.1</span> Chapter Overview</a></li>
<li><a href="probability-concepts.html#experiments-sample-spaces-and-events" id="toc-experiments-sample-spaces-and-events"><span class="toc-section-number">3.2</span> Experiments, Sample Spaces, and Events</a></li>
<li><a href="probability-concepts.html#probability-distributions" id="toc-probability-distributions"><span class="toc-section-number">3.3</span> Probability Distributions</a>
<ul>
<li><a href="probability-concepts.html#venn-diagrams" id="toc-venn-diagrams"><span class="toc-section-number">3.3.1</span> Venn Diagrams</a></li>
<li><a href="probability-concepts.html#probability-axioms" id="toc-probability-axioms"><span class="toc-section-number">3.3.2</span> Probability Axioms</a></li>
<li><a href="probability-concepts.html#exercises" id="toc-exercises">Exercises</a></li>
</ul></li>
<li><a href="probability-concepts.html#rules-of-probability" id="toc-rules-of-probability"><span class="toc-section-number">3.4</span> Rules of Probability</a>
<ul>
<li><a href="probability-concepts.html#addition-rules" id="toc-addition-rules"><span class="toc-section-number">3.4.1</span> Addition Rules</a></li>
<li><a href="probability-concepts.html#complements" id="toc-complements"><span class="toc-section-number">3.4.2</span> Complements</a></li>
</ul></li>
<li><a href="probability-concepts.html#conditional-probability" id="toc-conditional-probability"><span class="toc-section-number">3.5</span> Conditional Probability</a>
<ul>
<li><a href="probability-concepts.html#multiplication-rules" id="toc-multiplication-rules"><span class="toc-section-number">3.5.1</span> Multiplication Rules</a></li>
</ul></li>
</ul></li>
<li><a href="random-variables.html#random-variables" id="toc-random-variables"><span class="toc-section-number">4</span> Random Variables</a>
<ul>
<li><a href="random-variables.html#chapter-overview-3" id="toc-chapter-overview-3"><span class="toc-section-number">4.1</span> Chapter Overview</a></li>
<li><a href="random-variables.html#discrete-random-variables" id="toc-discrete-random-variables"><span class="toc-section-number">4.2</span> Discrete Random Variables</a>
<ul>
<li><a href="random-variables.html#the-mean-and-standard-deviation" id="toc-the-mean-and-standard-deviation"><span class="toc-section-number">4.2.1</span> The Mean and Standard Deviation</a></li>
</ul></li>
<li><a href="random-variables.html#the-binomial-distribution" id="toc-the-binomial-distribution"><span class="toc-section-number">4.3</span> The Binomial Distribution</a>
<ul>
<li><a href="random-variables.html#mean-and-variance" id="toc-mean-and-variance"><span class="toc-section-number">4.3.1</span> Mean and Variance</a></li>
<li><a href="random-variables.html#binomial-probabilities-in-r" id="toc-binomial-probabilities-in-r">Binomial Probabilities in R</a></li>
</ul></li>
<li><a href="random-variables.html#the-normal-distribution" id="toc-the-normal-distribution"><span class="toc-section-number">4.4</span> The Normal Distribution</a>
<ul>
<li><a href="random-variables.html#the-standard-normal-distribution" id="toc-the-standard-normal-distribution"><span class="toc-section-number">4.4.1</span> The Standard Normal Distribution</a></li>
</ul></li>
<li><a href="random-variables.html#area-under-the-standard-normal-curve" id="toc-area-under-the-standard-normal-curve"><span class="toc-section-number">4.5</span> Area Under the Standard Normal Curve</a>
<ul>
<li><a href="random-variables.html#r-normal-distribution-probabilities" id="toc-r-normal-distribution-probabilities">R: Normal Distribution Probabilities</a></li>
</ul></li>
<li><a href="random-variables.html#working-with-normally-distributed-variables" id="toc-working-with-normally-distributed-variables"><span class="toc-section-number">4.6</span> Working with Normally Distributed Variables</a>
<ul>
<li><a href="random-variables.html#normal-distribution-probabilities" id="toc-normal-distribution-probabilities"><span class="toc-section-number">4.6.1</span> Normal Distribution Probabilities</a></li>
<li><a href="random-variables.html#empirical-rule-for-variables" id="toc-empirical-rule-for-variables"><span class="toc-section-number">4.6.2</span> Empirical Rule for Variables</a></li>
<li><a href="random-variables.html#percentiles" id="toc-percentiles"><span class="toc-section-number">4.6.3</span> Percentiles</a></li>
</ul></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#introduction-to-confidence-intervals" id="toc-introduction-to-confidence-intervals"><span class="toc-section-number">5</span> Introduction to Confidence Intervals</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#chapter-overview-4" id="toc-chapter-overview-4"><span class="toc-section-number">5.1</span> Chapter Overview</a></li>
<li><a href="introduction-to-confidence-intervals.html#sampling-distributions" id="toc-sampling-distributions"><span class="toc-section-number">5.2</span> Sampling Distributions</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#sampling-error" id="toc-sampling-error"><span class="toc-section-number">5.2.1</span> Sampling Error</a></li>
<li><a href="introduction-to-confidence-intervals.html#the-central-limit-theorem" id="toc-the-central-limit-theorem"><span class="toc-section-number">5.2.2</span> The Central Limit Theorem</a></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#developing-confidence-intervals" id="toc-developing-confidence-intervals"><span class="toc-section-number">5.3</span> Developing Confidence Intervals</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#interpreting-a-confidence-interval" id="toc-interpreting-a-confidence-interval"><span class="toc-section-number">5.3.1</span> Interpreting a Confidence Interval</a></li>
<li><a href="introduction-to-confidence-intervals.html#exercises-1" id="toc-exercises-1"><span class="toc-section-number">5.3.2</span> Exercises</a></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#other-levels-of-confidence" id="toc-other-levels-of-confidence"><span class="toc-section-number">5.4</span> Other Levels of Confidence</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#r-finding-critical-values" id="toc-r-finding-critical-values">R: Finding Critical Values</a></li>
<li><a href="introduction-to-confidence-intervals.html#breaking-down-a-confidence-interval" id="toc-breaking-down-a-confidence-interval"><span class="toc-section-number">5.4.1</span> Breaking Down a Confidence Interval</a></li>
<li><a href="introduction-to-confidence-intervals.html#confidence-level-precision-and-sample-size" id="toc-confidence-level-precision-and-sample-size"><span class="toc-section-number">5.4.2</span> Confidence Level, Precision, and Sample Size</a></li>
<li><a href="introduction-to-confidence-intervals.html#exercises-2" id="toc-exercises-2"><span class="toc-section-number">5.4.3</span> Exercises</a></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#confidence-intervals-for-a-mean" id="toc-confidence-intervals-for-a-mean"><span class="toc-section-number">5.5</span> Confidence Intervals for a Mean</a>
<ul>
<li><a href="introduction-to-confidence-intervals.html#the-t-distribution" id="toc-the-t-distribution"><span class="toc-section-number">5.5.1</span> The T-Distribution</a></li>
<li><a href="introduction-to-confidence-intervals.html#r-t-critical-values" id="toc-r-t-critical-values">R: T Critical Values</a></li>
</ul></li>
<li><a href="introduction-to-confidence-intervals.html#r-confidence-intevals-for-a-mean" id="toc-r-confidence-intevals-for-a-mean">R: Confidence Intevals for a Mean</a></li>
</ul></li>
<li><a href="introduction-to-hypothesis-testing.html#introduction-to-hypothesis-testing" id="toc-introduction-to-hypothesis-testing"><span class="toc-section-number">6</span> Introduction to Hypothesis Testing</a>
<ul>
<li><a href="introduction-to-hypothesis-testing.html#chapter-overview-5" id="toc-chapter-overview-5"><span class="toc-section-number">6.1</span> Chapter Overview</a></li>
<li><a href="introduction-to-hypothesis-testing.html#logic-of-hypothesis-testing" id="toc-logic-of-hypothesis-testing"><span class="toc-section-number">6.2</span> Logic of Hypothesis Testing</a>
<ul>
<li><a href="introduction-to-hypothesis-testing.html#decision-errors" id="toc-decision-errors"><span class="toc-section-number">6.2.1</span> Decision Errors</a></li>
</ul></li>
<li><a href="introduction-to-hypothesis-testing.html#confidence-interval-approach-to-hypothesis-testing" id="toc-confidence-interval-approach-to-hypothesis-testing"><span class="toc-section-number">6.3</span> Confidence Interval Approach to Hypothesis Testing</a></li>
<li><a href="introduction-to-hypothesis-testing.html#critical-value-approach-to-hypothesis-testing" id="toc-critical-value-approach-to-hypothesis-testing"><span class="toc-section-number">6.4</span> Critical Value Approach to Hypothesis Testing</a>
<ul>
<li><a href="introduction-to-hypothesis-testing.html#test-statistics" id="toc-test-statistics"><span class="toc-section-number">6.4.1</span> Test statistics</a></li>
</ul></li>
<li><a href="introduction-to-hypothesis-testing.html#p-value-approach-to-hypothesis-testing" id="toc-p-value-approach-to-hypothesis-testing"><span class="toc-section-number">6.5</span> P-Value Approach to Hypothesis Testing</a>
<ul>
<li><a href="introduction-to-hypothesis-testing.html#p-values" id="toc-p-values"><span class="toc-section-number">6.5.1</span> P-Values</a></li>
</ul></li>
<li><a href="introduction-to-hypothesis-testing.html#r-hypothesis-tests-for-a-mean" id="toc-r-hypothesis-tests-for-a-mean">R: Hypothesis Tests for a Mean</a></li>
</ul></li>
<li><a href="inference-for-a-proportion.html#inference-for-a-proportion" id="toc-inference-for-a-proportion"><span class="toc-section-number">7</span> Inference for a Proportion</a>
<ul>
<li><a href="inference-for-a-proportion.html#chapter-overview-6" id="toc-chapter-overview-6"><span class="toc-section-number">7.1</span> Chapter Overview</a></li>
<li><a href="inference-for-a-proportion.html#confidence-intervals-for-a-proportion" id="toc-confidence-intervals-for-a-proportion"><span class="toc-section-number">7.2</span> Confidence Intervals for a Proportion</a></li>
<li><a href="inference-for-a-proportion.html#hypothesis-tests-for-a-proportion" id="toc-hypothesis-tests-for-a-proportion"><span class="toc-section-number">7.3</span> Hypothesis Tests for a Proportion</a>
<ul>
<li><a href="inference-for-a-proportion.html#confidence-interval-approach" id="toc-confidence-interval-approach"><span class="toc-section-number">7.3.1</span> Confidence Interval Approach</a></li>
<li><a href="inference-for-a-proportion.html#critical-value-approach" id="toc-critical-value-approach"><span class="toc-section-number">7.3.2</span> Critical Value Approach</a></li>
<li><a href="inference-for-a-proportion.html#p-value-approach" id="toc-p-value-approach"><span class="toc-section-number">7.3.3</span> P-Value Approach</a></li>
</ul></li>
<li><a href="inference-for-a-proportion.html#r-hypothesis-tests-for-a-proportion" id="toc-r-hypothesis-tests-for-a-proportion">R: Hypothesis Tests for a Proportion</a></li>
</ul></li>
<li><a href="inference-comparing-parameters.html#inference-comparing-parameters" id="toc-inference-comparing-parameters"><span class="toc-section-number">8</span> Inference: Comparing Parameters</a>
<ul>
<li><a href="inference-comparing-parameters.html#chapter-overview-7" id="toc-chapter-overview-7"><span class="toc-section-number">8.1</span> Chapter Overview</a></li>
<li><a href="inference-comparing-parameters.html#hypothesis-tests-for-two-proportions" id="toc-hypothesis-tests-for-two-proportions"><span class="toc-section-number">8.2</span> Hypothesis Tests for Two Proportions</a>
<ul>
<li><a href="inference-comparing-parameters.html#confidence-intervals-for-two-proportions" id="toc-confidence-intervals-for-two-proportions"><span class="toc-section-number">8.2.1</span> Confidence Intervals for Two Proportions</a></li>
<li><a href="inference-comparing-parameters.html#critical-values-test-statistics-and-p-values" id="toc-critical-values-test-statistics-and-p-values"><span class="toc-section-number">8.2.2</span> Critical Values, Test Statistics, and P-Values</a></li>
<li><a href="inference-comparing-parameters.html#r-hypothesis-tests-for-two-proportions" id="toc-r-hypothesis-tests-for-two-proportions">R: Hypothesis Tests for Two Proportions</a></li>
</ul></li>
<li><a href="inference-comparing-parameters.html#hypothesis-tests-for-two-means" id="toc-hypothesis-tests-for-two-means"><span class="toc-section-number">8.3</span> Hypothesis Tests for Two Means</a>
<ul>
<li><a href="inference-comparing-parameters.html#paired-samples" id="toc-paired-samples"><span class="toc-section-number">8.3.1</span> Paired Samples</a></li>
<li><a href="inference-comparing-parameters.html#independent-samples" id="toc-independent-samples"><span class="toc-section-number">8.3.2</span> Independent Samples</a></li>
<li><a href="inference-comparing-parameters.html#r-hypothesis-tests-for-two-means" id="toc-r-hypothesis-tests-for-two-means">R: Hypothesis Tests for Two Means</a></li>
</ul></li>
</ul></li>
<li><a href="chi-square-tests.html#chi-square-tests" id="toc-chi-square-tests"><span class="toc-section-number">9</span> Chi-Square Tests</a>
<ul>
<li><a href="chi-square-tests.html#chapter-overview-8" id="toc-chapter-overview-8"><span class="toc-section-number">9.1</span> Chapter Overview</a></li>
<li><a href="chi-square-tests.html#inference-for-a-population-variance" id="toc-inference-for-a-population-variance"><span class="toc-section-number">9.2</span> Inference for a Population Variance</a>
<ul>
<li><a href="chi-square-tests.html#the-chi-square-distribution" id="toc-the-chi-square-distribution"><span class="toc-section-number">9.2.1</span> The Chi-Square Distribution</a></li>
</ul></li>
<li><a href="chi-square-tests.html#the-ratio-of-two-variances" id="toc-the-ratio-of-two-variances"><span class="toc-section-number">9.3</span> The Ratio of Two Variances</a></li>
<li><a href="chi-square-tests.html#goodness-of-fit" id="toc-goodness-of-fit"><span class="toc-section-number">9.4</span> Goodness of Fit</a></li>
<li><a href="chi-square-tests.html#contingency-tables" id="toc-contingency-tables"><span class="toc-section-number">9.5</span> Contingency Tables</a></li>
</ul></li>
<li><a href="anova.html#anova" id="toc-anova"><span class="toc-section-number">10</span> ANOVA</a>
<ul>
<li><a href="anova.html#chapter-overview-9" id="toc-chapter-overview-9"><span class="toc-section-number">10.1</span> Chapter Overview</a></li>
<li><a href="anova.html#what-is-the-analysis-of-variance-anova" id="toc-what-is-the-analysis-of-variance-anova"><span class="toc-section-number">10.2</span> What is the Analysis of Variance (ANOVA)</a></li>
<li><a href="anova.html#the-f-distribution" id="toc-the-f-distribution"><span class="toc-section-number">10.3</span> The F-Distribution</a></li>
<li><a href="anova.html#multiple-comparisons-and-type-i-error-rate" id="toc-multiple-comparisons-and-type-i-error-rate"><span class="toc-section-number">10.4</span> Multiple Comparisons and Type I Error Rate</a></li>
</ul></li>
<li><a href="regression-and-correlation.html#regression-and-correlation" id="toc-regression-and-correlation"><span class="toc-section-number">11</span> Regression and Correlation</a>
<ul>
<li><a href="regression-and-correlation.html#chapter-overview-10" id="toc-chapter-overview-10"><span class="toc-section-number">11.1</span> Chapter Overview</a></li>
<li><a href="regression-and-correlation.html#linear-equations" id="toc-linear-equations"><span class="toc-section-number">11.2</span> Linear Equations</a></li>
<li><a href="regression-and-correlation.html#correlation" id="toc-correlation"><span class="toc-section-number">11.3</span> Correlation</a></li>
<li><a href="regression-and-correlation.html#finding-a-regression-line" id="toc-finding-a-regression-line"><span class="toc-section-number">11.4</span> Finding a Regression Line</a>
<ul>
<li><a href="regression-and-correlation.html#coefficient-of-determination" id="toc-coefficient-of-determination"><span class="toc-section-number">11.4.1</span> Coefficient of Determination</a></li>
</ul></li>
</ul></li>
<li><a href="appendices.html#appendices" id="toc-appendices">Appendices</a>
<ul>
<li><a href="appendices.html#appendix-a-important-links-and-additional-resources" id="toc-appendix-a-important-links-and-additional-resources">Appendix A: Important Links and Additional Resources</a>
<ul>
<li><a href="appendices.html#applets" id="toc-applets">Applets</a></li>
<li><a href="appendices.html#run-r-online" id="toc-run-r-online">Run R Online</a></li>
</ul></li>
<li><a href="appendices.html#appendix-b-average-deviance" id="toc-appendix-b-average-deviance">Appendix B: Average Deviance</a></li>
<li><a href="appendices.html#appendix-c-deriving-a-confidence-interval" id="toc-appendix-c-deriving-a-confidence-interval">Appendix C: Deriving a Confidence Interval</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-confidence-intervals" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Introduction to Confidence Intervals<a href="introduction-to-confidence-intervals.html#introduction-to-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="chapter-overview-4" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Chapter Overview<a href="introduction-to-confidence-intervals.html#chapter-overview-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter will bridge the gap between our discussion on the normal distribution and our first forays into statistical inference. As it turns out, much of the statistical inference we will use relies on the normal distribution and the t-distribution, which we will introduce in this chapter. We begin our study of statistical inference by learning about confidence intervals.</p>
<p><strong>Chapter Learning Objectives/Outcomes</strong></p>
<ol style="list-style-type: decimal">
<li>Find the distribution of a sample mean.</li>
<li>Estimate probabilities for a sample mean.</li>
<li>Calculate and interpret confidence intervals for a population mean.</li>
<li>Use the standard normal and t-distributions to find critical values.</li>
</ol>
<p><strong>R Objectives</strong></p>
<ol style="list-style-type: decimal">
<li>Find z and t critical values.</li>
<li>Generate complete confidence intervals for a population mean.</li>
</ol>
<p>This chapter’s outcomes correspond to course outcome (6) apply statistical inference techniques of parameter estimation such as point estimation and confidence interval estimation and (7) apply techniques of testing various statistical hypotheses concerning population parameters.</p>
</div>
<div id="sampling-distributions" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Sampling Distributions<a href="introduction-to-confidence-intervals.html#sampling-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="sampling-error" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Sampling Error<a href="introduction-to-confidence-intervals.html#sampling-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We want to use a sample to learn something about a population, but no sample is perfect! <strong>Sampling error</strong> is the error resulting from using a sample to estimate a population characteristic.</p>
<p>If we use a sample mean <span class="math inline">\(\bar{x}\)</span> to estimate <span class="math inline">\(\mu\)</span>, chances are that <span class="math inline">\(\bar{x}\ne\mu\)</span> (they might be close but… they might not be!). We will consider</p>
<ul>
<li>How close <em>is</em> <span class="math inline">\(\bar{x}\)</span> to <span class="math inline">\(\mu\)</span>?</li>
<li>What if we took many samples and calculated <span class="math inline">\(\bar{x}\)</span> many times?
<ul>
<li>How would that relate to <span class="math inline">\(\mu\)</span>?</li>
<li>What would be the distribution of these values?</li>
</ul></li>
</ul>
<p>The distribution of a statistic (across all possible samples of size <span class="math inline">\(n\)</span>) is called the <strong>sampling distribution</strong>. We will focus primarily on the distribution of the sample mean.</p>
<p>For a variable <span class="math inline">\(x\)</span> and given a sample size <span class="math inline">\(n\)</span>, the distribution of <span class="math inline">\(\bar{x}\)</span> is called the <strong>sampling distribution of the sample mean</strong> or the <strong>distribution of <span class="math inline">\(\boldsymbol{\bar{x}}\)</span></strong>.</p>
<blockquote>
<p><em>Example</em>: Suppose our population is the five starting players on a particular basketball team. We are interested in their heights (measures in inches). The full population data is</p>
<table>
<thead>
<tr class="header">
<th align="left">Player</th>
<th align="center">A</th>
<th align="center">B</th>
<th align="center">C</th>
<th align="center">D</th>
<th align="center">E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Height</td>
<td align="center">76</td>
<td align="center">78</td>
<td align="center">79</td>
<td align="center">81</td>
<td align="center">86</td>
</tr>
</tbody>
</table>
<p>The population mean is <span class="math inline">\(\mu=80\)</span>. Consider all possible samples of size <span class="math inline">\(n=2\)</span>:</p>
<table>
<colgroup>
<col width="6%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Sample</th>
<th align="center">A,B</th>
<th align="center">A,C</th>
<th align="center">A,D</th>
<th align="center">A,E</th>
<th align="center">B,C</th>
<th align="center">B,D</th>
<th align="center">B,E</th>
<th align="center">C,D</th>
<th align="center">C,E</th>
<th align="center">D,E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\bar{x}\)</span></td>
<td align="center">77</td>
<td align="center">77.5</td>
<td align="center">78.5</td>
<td align="center">81.0</td>
<td align="center">78.5</td>
<td align="center">79.5</td>
<td align="center">82.0</td>
<td align="center">80.0</td>
<td align="center">82.5</td>
<td align="center">83.5</td>
</tr>
</tbody>
</table>
<p>There are 10 possible samples of size 2. Of these samples, 10% have means exactly equal to <span class="math inline">\(\mu\)</span> (for a <em>random</em> sample of size 2, you’d have a 10% chance to find <span class="math inline">\(\bar{x}=\mu\)</span>… and a 90% chance not to!).</p>
</blockquote>
<p>In general, the larger the sample size, the smaller the sampling error tends to be in estimating <span class="math inline">\(\mu\)</span> using <span class="math inline">\(\bar{x}\)</span>.</p>
<p>In practice, we have one sample and <span class="math inline">\(\mu\)</span> is unknown. We also have limited resources to collect data, so it may not be feasible to collect a very large sample.</p>
<p>The mean of the distribution of <span class="math inline">\(\bar{x}\)</span> is <span class="math inline">\(\mu_{\bar{X}}=\mu\)</span> and the standard deviation is <span class="math inline">\(\sigma_{\bar{X}}=\sigma/\sqrt{n}\)</span>. We refer to the standard deviation of a sampling distribution as <strong>standard error</strong>. (Note that this standard error formula is built for very large populations, so it will not work well for our basketball players. This is okay! We usually work with populations so large that we treat them as “infinite”.)</p>
<blockquote>
<p><em>Example</em>: The mean living space for a detatched single family home in the United States is 1742 ft<span class="math inline">\(^2\)</span> with a standard deviation of 568 square feet. (Does that mean seem huge to anyone else??) For samples of 25 homes, determine the mean and standard error of <span class="math inline">\(\bar{x}\)</span>.</p>
<p>Using our formulae: <span class="math display">\[\mu_{\bar{X}} = \mu = 1742\]</span> and <span class="math display">\[\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{568}{\sqrt{25}} = 113.6.\]</span></p>
</blockquote>
</div>
<div id="the-central-limit-theorem" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> The Central Limit Theorem<a href="introduction-to-confidence-intervals.html#the-central-limit-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the setting where <span class="math inline">\(X\)</span> is Normal(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>). The plots below show (A) a random sample of 1000 from a Normal(100, 25) distribution and (B) the approximate sampling distribution of <span class="math inline">\(\bar{X}\)</span> when X is Normal(100, 25).</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p>Notice how the x-axis changes from one plot to the next.</p>
<p>In fact, if <span class="math inline">\(X\)</span> is Normal(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>), then <span class="math inline">\(\bar{X}\)</span> is Normal(<span class="math inline">\(\mu_{\bar{X}}=\mu\)</span>, <span class="math inline">\(\sigma_{\bar{X}}=\sigma/\sqrt{n}\)</span>).</p>
<p>Surprisingly, we see a similar result for <span class="math inline">\(\bar{X}\)</span> even when <span class="math inline">\(X\)</span> is not normally distributed!</p>
<center>
<font size='4'><b>Central Limit Theorem</b></font>
</center>
<p>For relatively large sample sizes, the random variable <span class="math inline">\(\bar{X}\)</span> is approximately normally distributed <em>regardless of the distribution of</em> <span class="math inline">\(X\)</span>: <span class="math display">\[\bar{X}\text{ is Normal}(\mu_{\bar{X}}=\mu, \sigma_{\bar{X}}=\sigma/\sqrt{n}).\]</span></p>
<p>Notes</p>
<ul>
<li>This approximation improves with increasing sample size.</li>
<li>In general, “relatively large” means sample sizes <span class="math inline">\(n \ge 30\)</span>.</li>
</ul>
</div>
</div>
<div id="developing-confidence-intervals" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Developing Confidence Intervals<a href="introduction-to-confidence-intervals.html#developing-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recall: A <strong>point estimate</strong> is a single-value estimate of a population parameter. We say that a statistic is an <strong>unbiased estimator</strong> if the mean of its distribution is equal to the population parameter. Otherwise, it is a <strong>biased estimator</strong>.</p>
<p><em>Comment</em>: Remember how our formula for sample variance, the “mean squared deviance” divides by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>? We do this so that <span class="math inline">\(s\)</span> is an <em>unbiased</em> estimate of <span class="math inline">\(\sigma\)</span>.</p>
<p>Ideally, we want estimates that are unbiased with small standard error. For example, a sample mean (unbiased) with a large sample size (results in smaller standard error).</p>
<p>Point estimates are useful, but they only give us so much information. The variability of an estimate is also important!</p>
<blockquote>
<p><em>Example</em> Think about estimating what tomorrow’s weather will be like. If it’s May in Sacramento, the average high temperature is 82 degrees Fahrenheit, but it’s not uncommon to have highs anywhere from 75 to 90! Since the highs are so <em>variable</em>, it’s hard to be confident using 82 to predict tomorrow’s weather.</p>
<p>On the flip side, think about July in Phoenix. The average high is 106 degrees Fahrenheit. In Phoenix, it’s uncommon to have a July day with a high below 100. Since the highs are <em>not variable</em>, you could feel pretty confident using 106 to predict tomorrow’s weather.</p>
</blockquote>
<p>Take a look at these two boxplots:</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
<p>Both samples are size <span class="math inline">\(n=100\)</span> and have <span class="math inline">\(\bar{x}=0\)</span>, which would be our point estimate for <span class="math inline">\(\mu\)</span>… but Variable 1 has a standard deviation of <span class="math inline">\(\sigma=0.5\)</span> and Variable 2 has standard deviation <span class="math inline">\(\sigma=5\)</span>. As a result, we can be more confident in our estimate of the population mean for Variable 1 than for Variable 2.</p>
<p>We want to formalize this idea of confidence in our estimates. A <strong>confidence interval</strong> is an interval of numbers based on the point estimate of the parameter. Say we want to be 95% confident about a statement. In Statistics, this means that we have arrived at our statement using a method that will give us a correct statement 95% of the time.</p>
<p>Our best point estimate for <span class="math inline">\(\mu\)</span> (based on a random sample) is <span class="math inline">\(\bar{x}\)</span>, so that value will make up the center (or midpoint) of the interval. To create an interval around <span class="math inline">\(\bar{x}\)</span>, we will construct what is called the <strong>margin of error</strong>. We will use the variability of the data along with some normal distribution properties. This will look like <span class="math display">\[z\times\frac{\sigma}{\sqrt{n}}\]</span> The value <span class="math inline">\(z\)</span> will come from the normal distribution and will be based on how confident we want to be, e.g., 95% confident.</p>
<p>Putting everything together, the 95% confidence interval is <span class="math display">\[\left(\bar{x} - z_*\frac{\sigma}{\sqrt{n}}, \bar{x} + z_*\frac{\sigma}{\sqrt{n}}\right)\]</span> where <span class="math inline">\(z_* = 1.96\)</span>. The value <span class="math inline">\(1.96\)</span> is chosen because <span class="math inline">\((-1.96 &lt; Z &lt; 1.96) = 0.95\)</span> (this is what makes it a 95% confidence interval!).</p>
<p><em>Note</em>: A more detailed mathematical explanation of how we get this interval is available in Appendix C.</p>
<div id="interpreting-a-confidence-interval" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Interpreting a Confidence Interval<a href="introduction-to-confidence-intervals.html#interpreting-a-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To interpret a confidence interval, we need to think back to our definition of probability as “the proportion of times an event would occur if the experiment were run infinitely many times”. In the confidence interval case, if an experiment is run infinitely many times, the true value of <span class="math inline">\(\mu\)</span> will be contained in 95% of the intervals.</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<p>The graphic above shows 95% confidence intervals for 100 samples of size <span class="math inline">\(n=60\)</span> drawn from a population with mean <span class="math inline">\(\mu=80\)</span> and standard deviation <span class="math inline">\(\sigma=25\)</span>. Each sample’s confidence interval is represented by a horizontal line. The dot in the middle of each is the sample mean. When a confidence interval does <em>not</em> capture the population mean <span class="math inline">\(\mu\)</span>, the line is printed in red. Based on this concept of repeated sampling, we would expect about 95% of these intervals to capture <span class="math inline">\(\mu\)</span>. In fact, 96 of the 100 intervals capture <span class="math inline">\(\mu\)</span>.</p>
<p>Finally, when you interpret a confidence interval, it is important to do so in the context of the problem.</p>
<blockquote>
<p><em>Example</em> The preferred keyboard height for typists is approximately normally distributed with <span class="math inline">\(\sigma=2.0\)</span>. A sample of size <span class="math inline">\(n=31\)</span>, resulted in a mean prefered keyboard height of <span class="math inline">\(80 cm\)</span>. Find and interpret a 95% confidence interval for keyboard height.</p>
<p>The interval is <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}} = 80.0 \pm 1.96\times\frac{2.0}{\sqrt{31}} = 80.0 \pm 0.70 = (79.3, 80.7).\]</span> Interpretation:We can be 95% confident that the mean preferred keyboard height for typists is between 79.3cm and 80.7cm.</p>
</blockquote>
<p>Notice that I kept the interpretation simple! That’s okay - just be sure you are <em>also</em> able to explain what it means to be 95% confident (using the concept of repeated sampling).</p>
<p>Common mistakes:</p>
<ul>
<li>It is NOT accurate to say that “the probability that <span class="math inline">\(\mu\)</span> is in the confidence interval is 0.95”. The parameter <span class="math inline">\(\mu\)</span> is some fixed quantity and it’s either in the interval or it isn’t.</li>
<li>We are NOT “95% confident that <span class="math inline">\(\bar{x}\)</span> is in the interval”. The value <span class="math inline">\(\bar{x}\)</span> is some known quantity and it’s always in the interval.</li>
</ul>
</div>
<div id="exercises-1" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Exercises<a href="introduction-to-confidence-intervals.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Suppose I took a random sample of 50 Sac State students and asked about their SAT scores and found a mean score of 1112. Prior experience with SAT scores in the CSU system suggests that SAT scores are well-approximated by a normal distribution with standard deviation known to be 50.
<ol style="list-style-type: lower-alpha">
<li>Find a 95% confidence interval for Sac State SAT scores.</li>
<li>Interpret your interval in the context of the problem.</li>
<li>What is the width of your interval? If you want a narrower interval, what could you do?</li>
</ol></li>
</ol>
</div>
</div>
<div id="other-levels-of-confidence" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Other Levels of Confidence<a href="introduction-to-confidence-intervals.html#other-levels-of-confidence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>While the 95% confidence interval is common in research, there’s nothing inherently special about it. You could calculate a 90%, a 99%, or - if you’re feeling spicy - something like a 43.8% confidence interval. These numbers are called the <strong>confidence level</strong> and they represent the proportion of times that the parameter will fall in the interval (if we took many samples).</p>
<p>The 100(1-<span class="math inline">\(\alpha\)</span>)% confidence interval for <span class="math inline">\(\mu\)</span> is given by <span class="math display">\[\bar{x}\pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\]</span> where <span class="math inline">\(z_{\alpha/2}\)</span> is the z-score associated with the <span class="math inline">\([1-(\alpha/2)]\)</span>th percentile of the standard normal distribution. The value <span class="math inline">\(z_{\alpha/2}\)</span> is called the <strong>critical value</strong> (“c.v.” on the plot, below).</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<center>
<font size='4'><b>Common Critical Values</b></font>
</center>
<table>
<thead>
<tr class="header">
<th align="center">Confidence Level</th>
<th align="center"><span class="math inline">\(\alpha\)</span></th>
<th align="center">Critical Value, <span class="math inline">\(z_{\alpha/2}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">90%</td>
<td align="center">0.10</td>
<td align="center">1.645</td>
</tr>
<tr class="even">
<td align="center">95%</td>
<td align="center">0.05</td>
<td align="center">1.96</td>
</tr>
<tr class="odd">
<td align="center">98%</td>
<td align="center">0.02</td>
<td align="center">2.326</td>
</tr>
<tr class="even">
<td align="center">99%</td>
<td align="center">0.01</td>
<td align="center">2.575</td>
</tr>
</tbody>
</table>
<div id="r-finding-critical-values" class="section level3 unnumbered hasAnchor">
<h3>R: Finding Critical Values<a href="introduction-to-confidence-intervals.html#r-finding-critical-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can find critical values in R using the same command we used to find percentiles: <code>qnorm</code>. Recall that <span class="math inline">\(z_{\alpha/2}\)</span> is the z-score associated with the <span class="math inline">\([1-(\alpha/2)]\)</span>th percentile of the standard normal distribution. So for a <span class="math inline">\((1-\alpha)100\%\)</span> confidence interval, we need to find the value of <span class="math inline">\(1-\alpha/2\)</span> to input into the <code>qnorm</code> command.</p>
<p>For example, to find <span class="math inline">\(z_{\alpha/2}\)</span> for a 93% confidence interval, we would use <span class="math display">\[(1-\alpha)100\% = 93\%\]</span> to solve for <span class="math inline">\(\alpha\)</span> and get <span class="math inline">\(\alpha = 0.07\)</span>. Then we need the <span class="math inline">\([1-(\alpha/2)]\)</span>th percentile: <span class="math display">\[1-\frac{\alpha}{2} = 1 - \frac{0.07}{2} = 0.965\]</span> Finally, we enter this value into the <code>qnorm</code> command:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="introduction-to-confidence-intervals.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.965</span>)</span></code></pre></div>
<pre><code>## [1] 1.811911</code></pre>
<p>and the critical value for a 93% confidence interval is <span class="math inline">\(z_{\alpha/2}=1.812\)</span>.</p>
</div>
<div id="breaking-down-a-confidence-interval" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Breaking Down a Confidence Interval<a href="introduction-to-confidence-intervals.html#breaking-down-a-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider <span class="math display">\[\left(\bar{x}- z_{\alpha/2}\frac{\sigma}{\sqrt{n}}, \quad \bar{x} + z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\right)\]</span> The key values are</p>
<ul>
<li><span class="math inline">\(\bar{x}\)</span>, the sample mean</li>
<li><span class="math inline">\(\sigma\)</span>, the population standard deviation</li>
<li><span class="math inline">\(n\)</span>, the sample size</li>
<li><span class="math inline">\(z_{\alpha/2}\)</span>, the critical value <span class="math display">\[P(Z &gt; z_{\alpha/2}) = \frac{\alpha}{2}\]</span></li>
</ul>
<p>The value of interest is <span class="math inline">\(\mu\)</span>, the (unknown) population mean; the confidence interval gives us a reasonable range of values for <span class="math inline">\(\mu\)</span>.</p>
<p>In addition, the formula includes</p>
<ul>
<li>The standard error, <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span></li>
<li>The margin of error, <span class="math inline">\(z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\)</span></li>
</ul>
</div>
<div id="confidence-level-precision-and-sample-size" class="section level3 hasAnchor" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Confidence Level, Precision, and Sample Size<a href="introduction-to-confidence-intervals.html#confidence-level-precision-and-sample-size" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we can be 99% confident (or even higher), why do we tend to “settle” for 95%?? Take a look at the common critical values (above) and the confidence interval formula <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}.\]</span> What will higher levels of confidence do to this interval? Think back to the intuitive interval width explanation with the weather. Mathematically, the same thing will happen: the interval will get wider! And remember, a narrow interval is a more informative interval. There is a trade off here between interval width and confidence. In general, the scientific community has settled on 95% as a compromise between the two, but different fields may use different levels of confidence.</p>
<p>There is one other thing we can control in the confidence interval: the sample size <span class="math inline">\(n\)</span>. One strategy is to specify the confidence level and the maximum acceptable interval width and use these to determine sample size. We know that <span class="math display">\[\text{interval width} \ge 2z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\]</span> (Note: I use <span class="math inline">\(\ge\)</span> because <span class="math inline">\(2z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\)</span> is the <em>maximum</em> interval width - we would still be happy if this value turned out to be smaller!) Letting interval width equal <span class="math inline">\(w\)</span>, we can solve for <span class="math inline">\(n\)</span>: <span class="math display">\[ n \ge \left(2z_{\alpha/2}\frac{\sigma}{w}\right)^2\]</span> Alternately, we may specify a maximum margin of error <span class="math inline">\(m\)</span> instead: <span class="math display">\[ n \ge \left(z_{\alpha/2}\frac{\sigma}{m}\right)^2\]</span> Once we’ve done this calculation, we need a whole number for <span class="math inline">\(n\)</span>. Since <span class="math inline">\(n \ge\)</span> something, we will <em>always round up</em>.</p>
<blockquote>
<p><em>Example</em> Suppose we want a 95% confidence interval for the mean of a normally distributed population with standard deviation <span class="math inline">\(\sigma=10\)</span>. It is important for our margin of error to be no more than 2. What sample size do we need?</p>
<p>Using the formula for sample size with a desired margin of error, I can plug in <span class="math inline">\(z_{0.05/2}=1.96\)</span>, <span class="math inline">\(m=2\)</span> and <span class="math inline">\(\sigma=10\)</span>: <span class="math display">\[n = \left(1.96\times\frac{10}{2}\right)^2 = 96.04\]</span>. So (rounding up!) I need a sample size of <em>at least 97</em>.</p>
</blockquote>
<p>A few comments:</p>
<ul>
<li>As desired width/margin of error decreases, <span class="math inline">\(n\)</span> will increase.</li>
<li>As <span class="math inline">\(\sigma\)</span> increases, <span class="math inline">\(n\)</span> will also increase. (More population variability will necessitate a larger sample size.)</li>
<li>As confidence level increases, <span class="math inline">\(n\)</span> will also increase.</li>
</ul>
</div>
<div id="exercises-2" class="section level3 hasAnchor" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Exercises<a href="introduction-to-confidence-intervals.html#exercises-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>In the previous section, you worked with a random sample of 50 Sac State students with mean SAT score 1112. Prior experience with SAT scores in the CSU system suggests that SAT scores are well-approximated by a normal distribution with standard deviation known to be 50. Calculate a
<ol style="list-style-type: lower-alpha">
<li>98% confidence interval.</li>
<li>90% confidence interval.</li>
<li>Interpret each interval in the context of the problem. Comment on how the intervals change as you change the confidence level.</li>
<li>Find the sample size required for a 98% confidence interval with maximum margin of error 10.</li>
</ol></li>
</ol>
</div>
</div>
<div id="confidence-intervals-for-a-mean" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Confidence Intervals for a Mean<a href="introduction-to-confidence-intervals.html#confidence-intervals-for-a-mean" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In practice, the value of <span class="math inline">\(\sigma\)</span> is almost never known… but we know that we can estimate <span class="math inline">\(\sigma\)</span> using <span class="math inline">\(s\)</span>. Can we plug in <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span>? Sometimes!</p>
<p>Remember the Central Limit Theorem (Section 5.1)? For samples of size <span class="math inline">\(n \ge 30\)</span>, <span class="math inline">\(\bar{X}\)</span> will be approximately normal even if <span class="math inline">\(X\)</span> isn’t. In this case, we can plug in <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span>: <span class="math display">\[\bar{x} \pm z_{\alpha/2}\frac{s}{\sqrt{n}}.\]</span></p>
<p>That setting is pretty straightforward! Now we need to consider the setting where <span class="math inline">\(n &lt; 30\)</span>, which will require a bit of additional work.</p>
<div id="the-t-distribution" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> The T-Distribution<a href="introduction-to-confidence-intervals.html#the-t-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Enter: the t-distribution. If <span class="math display">\[Z = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\]</span> has a standard normal distribution (for <span class="math inline">\(X\)</span> normal or <span class="math inline">\(n\ge30\)</span>), the slightly modified <span class="math display">\[T = \frac{\bar{X}-\mu}{s/\sqrt{n}}\]</span> has what we call the <strong>t-distribution</strong> with <span class="math inline">\(n-1\)</span> <strong>degrees of freedom</strong> (even when <span class="math inline">\(n &lt; 30\)</span>!). The only thing we need to know about degrees of freedom is that <span class="math inline">\(\text{df}=n-1\)</span> is the t-distribution’s only parameter.</p>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>The t-distribution is symmetric and always centered at 0. When <span class="math inline">\(n\ge30\)</span>, the t-distribution is approximately equivalent to the standard normal distribution. For smaller sample sizes, the t-distribution has more area in the tails (and therefore less area in the center of the distribution). Therefore, we can always use t confidence intervals (even if <span class="math inline">\(n\)</span> is large) because the critical values are essentially equivalent between the t and standard normal distributions for large values of <span class="math inline">\(n\)</span>. This is usually what happens in practice.</p>
<p>In practice, we plug in <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span> and almost always use a t critical value (instead of a z critical value): <span class="math inline">\(t_{\text{df}, \, \alpha/2}\)</span>. The t critical value is the <span class="math inline">\([1- \alpha/2]\)</span>th percentile of the t-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. The resulting 95% confidence interval is <span class="math display">\[\bar{x} \pm t_{\text{df}, \, \alpha/2}\frac{s}{\sqrt{n}}.\]</span></p>
<p>You may use the applet, <a href="http://www.rossmanchance.com/applets/2021/tcalc/tCalc.htm" target="blank">Rossman and Chance t Probability Calculator</a> to find t critical values. For this applet, enter the degrees of freedom <span class="math inline">\(n-1\)</span> next to “df”. Then check the top box under “t-value probability” and make sure the inequality is clicked to “&gt;” . Enter the value of <span class="math inline">\(\alpha/2\)</span> for the probability. Click anywhere else on the page and the applet will automatically fill in the box under “t-value”. This is your t critical value.</p>
</div>
<div id="r-t-critical-values" class="section level3 unnumbered hasAnchor">
<h3>R: T Critical Values<a href="introduction-to-confidence-intervals.html#r-t-critical-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To find a t critical value, we will again use R, now with the command <code>qt</code>. (Notice that this is similar to the command for the standard normal distribution, but instead of “norm” for normal it has “t” for the t-distribution.) The <code>qt</code> command takes in the following:</p>
<ul>
<li><code>p</code>, the probability</li>
<li><code>df</code>, the degrees of freedom</li>
</ul>
<p>For example, for a 98% interval with a sample size of 15, <span class="math display">\[100(1-\alpha) = 98 \implies \alpha=0.02\]</span> Then <span class="math inline">\(1-\alpha/2 = 0.99\)</span> and <span class="math inline">\(\text{df}=15-1=14\)</span>.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="introduction-to-confidence-intervals.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="at">p =</span> <span class="fl">0.99</span>, <span class="at">df =</span> <span class="dv">14</span>)</span></code></pre></div>
<pre><code>## [1] 2.624494</code></pre>
<p>which gives the t critical value <span class="math inline">\(t_{14,\alpha/2} = 2.625\)</span>.</p>
</div>
</div>
<div id="r-confidence-intevals-for-a-mean" class="section level2 unnumbered hasAnchor">
<h2>R: Confidence Intevals for a Mean<a href="introduction-to-confidence-intervals.html#r-confidence-intevals-for-a-mean" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To generate complete confidence intervals for a mean in R, we will use the command <code>t.test</code>. The two arguments we will use for confidence interval generation are</p>
<ul>
<li><code>x</code>: the variable that contains the data we want to use to construct a confidence interval.</li>
<li><code>conf.level</code>: the desired confidence level</li>
</ul>
<p>We will continue to use the <code>Loblolly</code> pine tree data.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="introduction-to-confidence-intervals.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Loblolly)</span></code></pre></div>
<p>In this case, the variable of interest is <code>x = height</code> and the desired confidence level is <code>conf.level = 0.95</code>. We our confidence interval using the following command:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="introduction-to-confidence-intervals.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> height, <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  height
## t = 14.348, df = 83, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  27.87796 36.85085
## sample estimates:
## mean of x 
##   32.3644</code></pre>
<p>R printed more information than we know what to do with right now. That’s ok! We will get to it later. Right now, focus your attention to where it says “95 percent confidence interval:” and the line below that, which gives the interval (27.88, 36.85). At the bottom, it also provides the sample mean height of 32.36 feet. Based on the R output, we can say that we are 95% confident that the true mean height of the loblolly pines is between 27.88 and 36.85 feet (assuming the researchers took a random sample of trees).</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="introduction-to-confidence-intervals.html#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(Loblolly)</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introduction-to-hypothesis-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IntroStats.pdf", "IntroStats.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
